"""
ë‚˜ë¼ì¥í„° Playwright ìë™í™” - ì‚¬ì—…ëª… í´ë¦­ â†’ ìƒì„¸í˜ì´ì§€ â†’ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
k00 íŒŒë¼ë¯¸í„° ìº¡ì²˜ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬ ì¸í„°ì…‰ì…˜
"""

import asyncio
import json
import os
import re
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright, Page, Request, Response
from urllib.parse import parse_qs, unquote


# ë‹¤ìš´ë¡œë“œ ì €ì¥ ê²½ë¡œ
DOWNLOAD_DIR = Path("/tmp/g2b_downloads")
DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)

# ìº¡ì²˜ëœ k00 ê°’ ì €ì¥
captured_k00_values = []


async def intercept_request(request: Request):
    """ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì¸í„°ì…‰íŠ¸ - k00 ìº¡ì²˜"""
    if "fileUpload.do" in request.url or "kupload" in request.url.lower():
        print(f"\nğŸ“¡ [INTERCEPT] File request: {request.url}")
        print(f"    Method: {request.method}")

        # POST bodyì—ì„œ k00 ì¶”ì¶œ
        if request.post_data:
            post_data = request.post_data
            print(f"    Post Data (first 500): {post_data[:500]}")

            # k00 íŒŒë¼ë¯¸í„° ì°¾ê¸°
            if "k00=" in post_data:
                k00_match = re.search(r'k00=([^&]+)', post_data)
                if k00_match:
                    k00_value = unquote(k00_match.group(1))
                    print(f"    âœ… k00 captured: {k00_value[:100]}...")
                    captured_k00_values.append({
                        "url": request.url,
                        "k00": k00_value,
                        "timestamp": datetime.now().isoformat()
                    })


async def intercept_response(response: Response):
    """ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ ì¸í„°ì…‰íŠ¸"""
    if "fileUpload.do" in response.url or "atch" in response.url.lower():
        print(f"\nğŸ“¥ [RESPONSE] {response.url}")
        print(f"    Status: {response.status}")
        content_type = response.headers.get("content-type", "")
        print(f"    Content-Type: {content_type}")

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‘ë‹µì¸ ê²½ìš°
        if "application" in content_type or "octet-stream" in content_type:
            content_disp = response.headers.get("content-disposition", "")
            print(f"    Content-Disposition: {content_disp}")


async def click_project_name_and_download(page: Page, keyword: str = "ì•¡ì…€ëŸ¬ë ˆì´íŒ…"):
    """í†µí•©ê²€ìƒ‰ â†’ ì‚¬ì—…ëª… í´ë¦­ â†’ ìƒì„¸í˜ì´ì§€ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""

    print("\n" + "=" * 60)
    print(f"ğŸ” ë‚˜ë¼ì¥í„° í†µí•©ê²€ìƒ‰: {keyword}")
    print("=" * 60)

    # 1. ë©”ì¸ í˜ì´ì§€ ì ‘ì†
    print("\n[1] ë‚˜ë¼ì¥í„° ë©”ì¸ í˜ì´ì§€ ì ‘ì†...")
    await page.goto("https://www.g2b.go.kr/")
    await page.wait_for_timeout(3000)

    # 2. íŒì—… ë‹«ê¸°
    print("\n[2] íŒì—… ë‹«ê¸°...")
    popup_close_selectors = [
        'button:has-text("ë‹«ê¸°")',
        'button:has-text("í™•ì¸")',
        '.popup-close',
        '.modal-close',
        '[class*="close"]',
        'a:has-text("ë‹«ê¸°")',
        '.btn-close',
        'button[aria-label="Close"]',
    ]

    for selector in popup_close_selectors:
        try:
            popups = await page.query_selector_all(selector)
            for popup in popups:
                if await popup.is_visible():
                    await popup.click(force=True)
                    print(f"    íŒì—… ë‹«ìŒ: {selector}")
                    await page.wait_for_timeout(500)
        except:
            continue

    await page.wait_for_timeout(1000)

    # ìŠ¤í¬ë¦°ìƒ· (íŒì—… ë‹«ì€ í›„)
    await page.screenshot(path=str(DOWNLOAD_DIR / "after_popup_close.png"))

    # 3. í†µí•©ê²€ìƒ‰ í´ë¦­
    print("\n[3] í†µí•©ê²€ìƒ‰ í´ë¦­...")
    unified_search_selectors = [
        'a:has-text("í†µí•©ê²€ìƒ‰")',
        'button:has-text("í†µí•©ê²€ìƒ‰")',
        '[class*="search"] a',
        'input[placeholder*="ê²€ìƒ‰"]',
        '#searchKeyword',
        '.search-box input',
    ]

    for selector in unified_search_selectors:
        try:
            elem = await page.wait_for_selector(selector, timeout=3000)
            if elem:
                await elem.click()
                print(f"    í´ë¦­: {selector}")
                await page.wait_for_timeout(1000)
                break
        except:
            continue

    # 4. ê²€ìƒ‰ì–´ ì…ë ¥
    print(f"\n[4] ê²€ìƒ‰ì–´ ì…ë ¥: {keyword}")

    # í†µí•©ê²€ìƒ‰ ì…ë ¥ì°½ ì°¾ê¸°
    search_input_selectors = [
        'input[placeholder*="ê²€ìƒ‰ì–´"]',
        'input[placeholder*="ê²€ìƒ‰"]',
        '#searchKeyword',
        '.search-input',
        'input[type="search"]',
        'input[type="text"]',
    ]

    search_input = None
    for selector in search_input_selectors:
        try:
            inputs = await page.query_selector_all(selector)
            for inp in inputs:
                if await inp.is_visible():
                    search_input = inp
                    print(f"    ì…ë ¥ì°½ ë°œê²¬: {selector}")
                    break
            if search_input:
                break
        except:
            continue

    if search_input:
        await search_input.fill(keyword)
        await page.wait_for_timeout(500)
        # Enter í‚¤ ëˆŒëŸ¬ì„œ ê²€ìƒ‰
        await search_input.press("Enter")
        print("    Enter í‚¤ë¡œ ê²€ìƒ‰ ì‹¤í–‰")
    else:
        print("    âš ï¸ ê²€ìƒ‰ ì…ë ¥ì°½ì„ ì°¾ì§€ ëª»í•¨")

    await page.wait_for_timeout(4000)

    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ê²€ìƒ‰ ê²°ê³¼)
    await page.screenshot(path=str(DOWNLOAD_DIR / "search_result.png"))
    print(f"    ê²€ìƒ‰ ê²°ê³¼ ìŠ¤í¬ë¦°ìƒ·: {DOWNLOAD_DIR / 'search_result.png'}")

    # 5. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ì—…ëª… ë§í¬ ì°¾ê¸°
    print("\n[5] ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ì—…ëª… ë§í¬ ì°¾ê¸°...")

    # í†µí•©ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ì—…ëª… ë§í¬ ì°¾ê¸°
    project_link = None

    # ë°©ë²• 1: WebSquare ê·¸ë¦¬ë“œì—ì„œ ë§í¬ ì°¾ê¸°
    try:
        # w2anchor2 í´ë˜ìŠ¤ê°€ ì‹¤ì œ í´ë¦­ ê°€ëŠ¥í•œ ë§í¬
        links = await page.query_selector_all('.w2anchor2, [class*="anchor"], a[onclick]')
        for link in links:
            text = await link.text_content()
            # ì•¡ì…€ëŸ¬ë ˆì´íŒ… í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì‹¤ì œ ì‚¬ì—…ëª… ì°¾ê¸°
            if text and keyword in text:
                if len(text.strip()) > 15 and "ìˆ˜ìˆ˜ë£Œ" not in text:
                    print(f"    Found project: {text[:60]}...")
                    project_link = link
                    break
    except Exception as e:
        print(f"    WebSquare ê·¸ë¦¬ë“œ íƒìƒ‰ ì‹¤íŒ¨: {e}")

    # ë°©ë²• 2: í…Œì´ë¸” í–‰ì—ì„œ ì°¾ê¸°
    if not project_link:
        try:
            rows = await page.query_selector_all('[class*="w2tb_td"], [class*="grid"] [class*="row"], tr')
            for row in rows:
                links = await row.query_selector_all('a, [class*="anchor"]')
                for link in links:
                    text = await link.text_content()
                    if text and keyword in text:
                        if len(text.strip()) > 15 and "ìˆ˜ìˆ˜ë£Œ" not in text:
                            print(f"    Found project in row: {text[:60]}...")
                            project_link = link
                            break
                if project_link:
                    break
        except Exception as e:
            print(f"    í…Œì´ë¸” íƒìƒ‰ ì‹¤íŒ¨: {e}")

    # ë°©ë²• 3: í˜ì´ì§€ ë‚´ ëª¨ë“  í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œì—ì„œ ê²€ìƒ‰
    if not project_link:
        print("    ëŒ€ì•ˆ ë°©ë²•: ì „ì²´ í˜ì´ì§€ íƒìƒ‰...")
        all_elements = await page.query_selector_all('a, button, [onclick], [class*="link"]')
        for elem in all_elements:
            text = await elem.text_content()
            if text and keyword in text:
                if len(text.strip()) > 15 and not any(skip in text for skip in ["ìˆ˜ìˆ˜ë£Œ", "ì•ˆë‚´", "ë¡œê·¸ì¸", "ê²€ìƒ‰"]):
                    print(f"    Found candidate: {text[:60]}...")
                    project_link = elem
                    break

    if project_link:
        print("\n[6] ì‚¬ì—…ëª… ë§í¬ í´ë¦­...")
        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ (ë””ë²„ê¹…ìš©)
        await page.screenshot(path=str(DOWNLOAD_DIR / "before_click.png"))
        print(f"    ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {DOWNLOAD_DIR / 'before_click.png'}")

        # JavaScriptë¡œ ì§ì ‘ í´ë¦­ (ê°€ì¥ ì•ˆì •ì )
        try:
            await project_link.evaluate("el => el.click()")
            print("    JavaScript í´ë¦­ ì„±ê³µ")
        except Exception as e:
            print(f"    JavaScript í´ë¦­ ì‹¤íŒ¨: {e}")
            # force click ì‹œë„
            try:
                await project_link.click(force=True, timeout=5000)
                print("    Force í´ë¦­ ì„±ê³µ")
            except Exception as e2:
                print(f"    Force í´ë¦­ë„ ì‹¤íŒ¨: {e2}")

        await page.wait_for_timeout(3000)

        # ìƒˆ íƒ­ì´ ì—´ë ¸ëŠ”ì§€ í™•ì¸
        pages = page.context.pages
        if len(pages) > 1:
            detail_page = pages[-1]
            print(f"    ìƒˆ íƒ­ ì—´ë¦¼: {detail_page.url}")
        else:
            detail_page = page

        # ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·
        await page.wait_for_timeout(2000)
        await detail_page.screenshot(path=str(DOWNLOAD_DIR / "detail_page.png"))
        print(f"    ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·: {DOWNLOAD_DIR / 'detail_page.png'}")

        # ëª¨ë‹¬ ë‚´ ìŠ¤í¬ë¡¤ ë‹¤ìš´ (ì²¨ë¶€íŒŒì¼ ì„¹ì…˜ ì°¾ê¸°)
        print("\n[7] ì²¨ë¶€íŒŒì¼ ì„¹ì…˜ ì°¾ê¸°...")

        # ì²¨ë¶€íŒŒì¼ ê´€ë ¨ ì•„ì½”ë””ì–¸/ì„¹ì…˜ í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°
        attachment_section_selectors = [
            'button:has-text("ì²¨ë¶€")',
            'a:has-text("ì²¨ë¶€")',
            '[class*="accordion"]:has-text("ì²¨ë¶€")',
            'div:has-text("ì²¨ë¶€íŒŒì¼")',
            '.w2group:has-text("ì²¨ë¶€")',
        ]

        for selector in attachment_section_selectors:
            try:
                section = await detail_page.query_selector(selector)
                if section:
                    await section.click()
                    print(f"    ì²¨ë¶€íŒŒì¼ ì„¹ì…˜ í´ë¦­: {selector}")
                    await page.wait_for_timeout(1000)
                    break
            except:
                continue

        # ëª¨ë‹¬/ë‹¤ì´ì–¼ë¡œê·¸ ë‚´ì—ì„œ ìŠ¤í¬ë¡¤ ë‹¤ìš´
        try:
            modal = await detail_page.query_selector('.modal, [class*="dialog"], [class*="popup"], [class*="layer"]')
            if modal:
                await modal.evaluate('el => el.scrollTop = el.scrollHeight')
                print("    ëª¨ë‹¬ ìŠ¤í¬ë¡¤ ë‹¤ìš´")
            else:
                # í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤
                await detail_page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                print("    í˜ì´ì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´")
        except:
            pass

        await page.wait_for_timeout(1000)
        await detail_page.screenshot(path=str(DOWNLOAD_DIR / "detail_page_scrolled.png"))
        print(f"    ìŠ¤í¬ë¡¤ í›„ ìŠ¤í¬ë¦°ìƒ·: {DOWNLOAD_DIR / 'detail_page_scrolled.png'}")

        # 8. ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ íƒìƒ‰
        print("\n[8] ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ íƒìƒ‰...")

        # HWP, PDF ë“± íŒŒì¼ í™•ì¥ìê°€ í¬í•¨ëœ ë§í¬ ì°¾ê¸°
        file_links = []

        # ë°©ë²• 1: kupload ê·¸ë¦¬ë“œ ë‚´ íŒŒì¼ëª… ì…€ ì°¾ê¸°
        try:
            # kupload íŒŒì¼ ëª©ë¡ì—ì„œ íŒŒì¼ëª… í´ë¦­ ìš”ì†Œ ì°¾ê¸°
            kupload_cells = await detail_page.query_selector_all('[class*="kupload"] td, [class*="raon"] td, [class*="w2grid"] td')
            for cell in kupload_cells:
                text = await cell.text_content() or ""
                if any(ext in text.lower() for ext in ['.hwp', '.pdf', '.xlsx', '.docx', '.zip']):
                    # ì…€ ë‚´ í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œ ì°¾ê¸°
                    clickable = await cell.query_selector('a, span, div')
                    if clickable:
                        print(f"    ğŸ“ kupload íŒŒì¼ ë°œê²¬: {text[:50]}")
                        file_links.append(clickable)
                    else:
                        file_links.append(cell)
        except Exception as e:
            print(f"    kupload íƒìƒ‰ ì‹¤íŒ¨: {e}")

        # ë°©ë²• 2: ì¼ë°˜ ë§í¬/ìš”ì†Œì—ì„œ ì°¾ê¸°
        if not file_links:
            all_elements = await detail_page.query_selector_all('a, [onclick], [class*="file"], [class*="down"], span, td')
            for elem in all_elements:
                text = await elem.text_content() or ""
                onclick = await elem.get_attribute('onclick') or ""
                # íŒŒì¼ í™•ì¥ì í¬í•¨ ì—¬ë¶€ í™•ì¸
                if any(ext in text.lower() for ext in ['.hwp', '.pdf', '.xlsx', '.docx', '.zip']):
                    print(f"    ğŸ“ íŒŒì¼ ë°œê²¬: {text[:50]}")
                    file_links.append(elem)
                elif 'download' in onclick.lower() or 'filedown' in onclick.lower():
                    print(f"    ğŸ“ ë‹¤ìš´ë¡œë“œ ë§í¬: {text[:50] if text else onclick[:50]}")
                    file_links.append(elem)

        # 9. íŒŒì¼ ë‹¤ìš´ë¡œë“œ í´ë¦­ (k00 ìº¡ì²˜ë¥¼ ìœ„í•´)
        print("\n[9] íŒŒì¼ ë‹¤ìš´ë¡œë“œ í´ë¦­ (k00 ìº¡ì²˜)...")

        if file_links:
            for i, file_link in enumerate(file_links[:3]):  # ìµœëŒ€ 3ê°œ íŒŒì¼ ì‹œë„
                try:
                    text = await file_link.text_content() or f"íŒŒì¼ {i+1}"
                    print(f"    ë‹¤ìš´ë¡œë“œ ì‹œë„: {text[:50]}")

                    # JavaScript í´ë¦­ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ íŠ¸ë¦¬ê±°
                    await file_link.evaluate("el => el.click()")
                    await page.wait_for_timeout(3000)  # ë‹¤ìš´ë¡œë“œ ìš”ì²­ ëŒ€ê¸°

                except Exception as e:
                    print(f"    ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("    íŒŒì¼ ë§í¬ë¥¼ ì°¾ì§€ ëª»í•¨. í˜ì´ì§€ ë‚´ ëª¨ë“  í´ë¦­ ê°€ëŠ¥ ìš”ì†Œ íƒìƒ‰...")
            # ëŒ€ì•ˆ: kupload ê´€ë ¨ ìš”ì†Œ ì°¾ê¸°
            kupload_elements = await detail_page.query_selector_all('[class*="kupload"], [id*="kupload"], [class*="raon"]')
            for elem in kupload_elements:
                text = await elem.text_content()
                if text:
                    print(f"    kupload ìš”ì†Œ: {text[:50]}")
    else:
        print("    âŒ ì‚¬ì—…ëª… ë§í¬ë¥¼ ì°¾ì§€ ëª»í•¨")

        # ë””ë²„ê¹…: í˜„ì¬ í˜ì´ì§€ HTML ì €ì¥
        html = await page.content()
        debug_path = DOWNLOAD_DIR / "debug_page.html"
        debug_path.write_text(html, encoding="utf-8")
        print(f"    ë””ë²„ê·¸ HTML ì €ì¥: {debug_path}")

    return captured_k00_values


async def run_automation(keyword: str = "ì•¡ì…€ëŸ¬ë ˆì´íŒ…"):
    """ë©”ì¸ ìë™í™” ì‹¤í–‰"""

    async with async_playwright() as p:
        # ì‹¤ì œ Chrome ë¸Œë¼ìš°ì € ì‚¬ìš© (ë‚˜ë¼ì¥í„°ê°€ Chromium ì°¨ë‹¨í•¨)
        browser = await p.chromium.launch(
            channel="chrome",  # ì‹¤ì œ ì„¤ì¹˜ëœ Chrome ì‚¬ìš©
            headless=False,  # Trueë¡œ ë³€ê²½í•˜ë©´ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
            slow_mo=300,  # ë””ë²„ê¹…ìš© ë”œë ˆì´
        )

        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},  # í’€HD ì‚¬ì´ì¦ˆë¡œ ë³€ê²½
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            accept_downloads=True,
            locale="ko-KR",
        )

        # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •
        page = await context.new_page()

        # ë„¤íŠ¸ì›Œí¬ ì¸í„°ì…‰ì…˜ ì„¤ì •
        page.on("request", intercept_request)
        page.on("response", intercept_response)

        try:
            # ìë™í™” ì‹¤í–‰
            k00_list = await click_project_name_and_download(page, keyword)

            # ê²°ê³¼ ì €ì¥
            if k00_list:
                result_path = DOWNLOAD_DIR / "captured_k00.json"
                result_path.write_text(
                    json.dumps(k00_list, ensure_ascii=False, indent=2),
                    encoding="utf-8"
                )
                print(f"\nâœ… k00 ê°’ ì €ì¥ë¨: {result_path}")

            # ë””ë²„ê¹…ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
            print("\nâ³ ë¸Œë¼ìš°ì € í™•ì¸ ì¤‘... (30ì´ˆ í›„ ìë™ ì¢…ë£Œ)")
            await page.wait_for_timeout(30000)

        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
        finally:
            await browser.close()

    return captured_k00_values


if __name__ == "__main__":
    print("=" * 60)
    print("ë‚˜ë¼ì¥í„° Playwright ìë™í™”")
    print("=" * 60)

    results = asyncio.run(run_automation("ì•¡ì…€ëŸ¬ë ˆì´íŒ…"))

    print("\n" + "=" * 60)
    print("ğŸ“Š ìº¡ì²˜ëœ k00 ê°’:")
    print("=" * 60)
    for item in results:
        print(json.dumps(item, ensure_ascii=False, indent=2))
