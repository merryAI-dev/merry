"""
VC íˆ¬ì ë¶„ì„ ì—ì´ì „íŠ¸ - Claude Code ìŠ¤íƒ€ì¼

ì‹¤í–‰: streamlit run app.py
"""

import asyncio
import re
from datetime import datetime
import io
import textwrap
from pathlib import Path
from typing import Optional
import streamlit as st

from shared.config import (
    get_avatar_image,
    get_user_avatar_image,
    initialize_session_state,
    initialize_agent,
)
from shared.auth import check_authentication
from shared.file_utils import (
    ALLOWED_EXTENSIONS_PDF,
    ALLOWED_EXTENSIONS_EXCEL,
    cleanup_user_temp_files,
    get_secure_upload_path,
    validate_upload,
)
from shared.logging_config import setup_logging
from agent.tools import (
    execute_read_pdf_as_text,
    execute_extract_pdf_market_evidence,
    execute_read_excel_as_text,
    execute_read_docx_as_text,
)
from dolphin_service.processor import process_documents_batch

# ë¡œê¹… ì´ˆê¸°í™”
setup_logging()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë©”ë¦¬ | VC ì—ì´ì „íŠ¸",
    page_icon="M",
    layout="wide",
    initial_sidebar_state="collapsed"  # ì‚¬ì´ë“œë°” ìˆ¨ê¹€
)

# ì´ˆê¸°í™” ë° ì¸ì¦
initialize_session_state()
check_authentication()  # ì¸ì¦ë˜ì§€ ì•Šìœ¼ë©´ ì—¬ê¸°ì„œ ë©ˆì¶¤

# ========================================
# í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì‚¬ì „ ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œ ìºì‹±)
# ========================================
from shared.airtable_portfolio import _get_cached_dataframe

# ì•± ì‹œì‘ ì‹œ DataFrame ë¯¸ë¦¬ ë¡œë“œ (ì²« ê²€ìƒ‰ë¶€í„° ë¹ ë¥´ê²Œ)
# @st.cache_dataë¡œ ìºì‹±ë˜ë¯€ë¡œ í•œ ë²ˆë§Œ ì‹¤í–‰ë¨
try:
    with st.spinner("ğŸ“Š íˆ¬ì ë°ì´í„° ë¡œë”© ì¤‘..."):
        df = _get_cached_dataframe()
        portfolio_size = len(df)

        st.session_state["portfolio_preloaded"] = True
        st.session_state["portfolio_size"] = portfolio_size

        # ì„±ê³µ ë©”ì‹œì§€ (2ì´ˆ í›„ ì‚¬ë¼ì§)
        success_container = st.empty()
        success_container.success(f"âœ… íˆ¬ì ë°ì´í„° ë¡œë”© ì™„ë£Œ! ({portfolio_size}ê°œ ê¸°ì—…)")
        import time
        time.sleep(2)
        success_container.empty()

except Exception as e:
    st.session_state["portfolio_preloaded"] = False
    st.session_state["portfolio_error"] = str(e)
    st.error(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")

# ========================================
# Claude Code ìŠ¤íƒ€ì¼ CSS
# ========================================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=IBM+Plex+Mono:wght@400;500&display=swap');

/* ì „ì—­ ìŠ¤íƒ€ì¼ - ë‹¤í¬ í…Œë§ˆ */
:root {
    --bg-primary: #0f0f0f;
    --bg-secondary: #1a1a1a;
    --border-color: #2a2a2a;
    --text-primary: #e4e4e7;
    --text-secondary: #a1a1aa;
    --accent: #3b82f6;
    --accent-hover: #2563eb;
    --tool-bg: #1a1a1a;
    --tool-border: #2a2a2a;
    --success: #10b981;
    --warning: #f59e0b;
}

html, body, [class*="css"] {
    font-family: 'Inter', 'Noto Sans KR', sans-serif;
    color: var(--text-primary);
    background-color: var(--bg-primary) !important;
}

/* ì‚¬ì´ë“œë°” ì™„ì „íˆ ìˆ¨ê¹€ */
[data-testid="stSidebar"] {
    display: none !important;
}

/* ë©”ì¸ ì»¨í…Œì´ë„ˆ */
.stApp {
    background-color: var(--bg-primary) !important;
}

.main .block-container {
    max-width: 900px;
    padding-top: 2rem;
    padding-bottom: 6rem;
}

/* í—¤ë” */
.claude-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 1rem 0;
    border-bottom: 1px solid var(--border-color);
    margin-bottom: 2rem;
}

.claude-header__logo {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    font-size: 1.125rem;
    font-weight: 600;
    color: var(--text-primary);
}

.claude-header__badge {
    display: inline-flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    background: var(--bg-secondary);
    font-size: 0.75rem;
    font-weight: 500;
    color: var(--text-secondary);
    border: 1px solid var(--border-color);
}

/* Welcome í™”ë©´ */
.welcome-screen {
    text-align: center;
    padding: 4rem 2rem;
    max-width: 600px;
    margin: 0 auto;
}

.welcome-screen__title {
    font-size: 1.875rem;
    font-weight: 600;
    margin-bottom: 0.75rem;
}

.welcome-screen__subtitle {
    font-size: 1rem;
    color: var(--text-secondary);
    margin-bottom: 3rem;
}

.capability-pills {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
    justify-content: center;
    margin-bottom: 2rem;
}

/* Tool Use ì¹´ë“œ (Claude Code ìŠ¤íƒ€ì¼) */
.tool-card {
    margin: 1rem 0;
    border: 1px solid var(--tool-border);
    border-radius: 0.5rem;
    background: var(--tool-bg);
    overflow: hidden;
}

.tool-card__header {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0.75rem 1rem;
    background: var(--bg-primary);
    border-bottom: 1px solid var(--tool-border);
    font-family: 'IBM Plex Mono', monospace;
    font-size: 0.875rem;
    font-weight: 500;
}

.tool-card__body {
    padding: 1rem;
    font-size: 0.875rem;
    line-height: 1.5;
}

.tool-card--running {
    border-color: var(--accent);
}

.tool-card--success {
    border-color: var(--success);
}

.tool-card--error {
    border-color: var(--warning);
}

/* ìŠ¤í”¼ë„ˆ (ì‹¤í–‰ ì¤‘) */
.tool-spinner {
    display: inline-block;
    width: 14px;
    height: 14px;
    border: 2px solid var(--tool-border);
    border-top-color: var(--accent);
    border-radius: 50%;
    animation: spin 0.8s linear infinite;
}

@keyframes spin {
    to { transform: rotate(360deg); }
}

/* íŒŒì¼ ì¹© */
.file-chip {
    display: inline-flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0.375rem 0.75rem;
    border-radius: 0.375rem;
    background: var(--bg-secondary);
    border: 1px solid var(--border-color);
    font-size: 0.875rem;
    margin: 0.25rem;
}

/* í•˜ë‹¨ ê³ ì • íŒŒì¼ ì˜ì—­ */
.fixed-file-area {
    max-width: 900px;
    margin: 0 auto 0.5rem auto;
    padding: 0.5rem 0;
}

/* Streamlit ê¸°ë³¸ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
div[data-testid="stButton"] button {
    background: var(--bg-secondary) !important;
    border: 1px solid var(--border-color) !important;
    color: var(--text-primary) !important;
    border-radius: 0.5rem !important;
    font-size: 0.875rem !important;
    font-weight: 500 !important;
    padding: 0.5rem 1rem !important;
}

div[data-testid="stButton"] button:hover {
    background: var(--bg-primary) !important;
    border-color: var(--accent) !important;
    color: var(--accent) !important;
}

/* ê²Œì„ ë¡œë”© íŒ ë°°ë„ˆ */
.loading-tips-banner {
    position: fixed;
    bottom: 0;
    left: 0;
    right: 0;
    background: linear-gradient(90deg, #1a1a1a 0%, #2a2a2a 50%, #1a1a1a 100%);
    border-top: 1px solid var(--border-color);
    padding: 0.75rem 1rem;
    z-index: 999;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.75rem;
}

.loading-tips-banner__icon {
    color: var(--success);
    font-size: 1rem;
    animation: pulse 2s ease-in-out infinite;
}

@keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
}

.loading-tips-banner__text {
    color: var(--text-secondary);
    font-size: 0.8125rem;
    max-width: 800px;
    text-align: center;
    transition: opacity 0.5s ease-in-out;
}

.report-preparse-status {
    width: 100%;
    white-space: normal;
    word-break: break-all;
    overflow-wrap: anywhere;
}

/* ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ìš”ì•½) ìŠ¤íƒ€ì¼ */
.system-message {
    background: rgba(59, 130, 246, 0.1);
    border-left: 3px solid var(--accent);
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
    margin: 1rem 0;
    font-size: 0.875rem;
}
</style>
""", unsafe_allow_html=True)

# ========================================
# í—¤ë”
# ========================================
# í—¤ë”: 3ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ (ì œëª©, íŒ€ ì„ íƒ, ìƒˆ ëŒ€í™” ë²„íŠ¼)
col_left, col_mid, col_right = st.columns([3, 2, 1])

with col_left:
    st.markdown("""
    <div class="claude-header">
        <div class="claude-header__logo">
            <span>Merry</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

with col_mid:
    # íŒ€ ë“œë¡­ë‹¤ìš´
    team_options = [
        "CIC ë´„ë‚ ",
        "CIC ìŠ¤í…œ",
        "CIC ì¬",
        "CIC ëª¨ëª¨",
        "LSê·¸ë£¹",
        "CIê·¸ë£¹",
        "ëŒ€í‘œì´ì‚¬ì‹¤"
    ]
    current_team = st.session_state.get("current_team", "CIC ë´„ë‚ ")
    selected_team = st.selectbox(
        "íŒ€ ì„ íƒ",
        options=team_options,
        index=team_options.index(current_team) if current_team in team_options else 0,
        key="team_selector",
        label_visibility="collapsed"
    )
    if selected_team != current_team:
        st.session_state.current_team = selected_team
        st.rerun()

with col_right:
    if st.button("ìƒˆ ëŒ€í™”", key="new_chat", help="ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.unified_messages = []
        st.session_state.unified_files = []
        st.rerun()

# ë¹ ë¥¸ í˜ì´ì§€ ì´ë™ (ì‚¬ì´ë“œë°” ìˆ¨ê¹€ ë³´ì™„)
st.markdown("### ë°”ë¡œê°€ê¸°")
nav_cols = st.columns(5)
with nav_cols[0]:
    st.page_link("pages/10_Fund_Dashboard.py", label="í€ë“œ ëŒ€ì‹œë³´ë“œ", icon="ğŸ“Š")
with nav_cols[1]:
    st.page_link("pages/0_Collaboration_Hub.py", label="í˜‘ì—… í—ˆë¸Œ", icon="ğŸ§­")
with nav_cols[2]:
    st.page_link("pages/8_Startup_Discovery.py", label="ìŠ¤íƒ€íŠ¸ì—… ë°œêµ´", icon="ğŸ”")
with nav_cols[3]:
    st.page_link("pages/11_Fund_Company_View.py", label="í€ë“œ/ê¸°ì—… ìƒì„¸", icon="ğŸ·ï¸")
with nav_cols[4]:
    st.page_link("pages/12_Fund_Newsletter.py", label="í€ë“œ ë‰´ìŠ¤ë ˆí„°", icon="ğŸ“°")

# ========================================
# ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
# ========================================
from shared.conversation_history import list_conversations, load_conversation, save_conversation

current_team = st.session_state.get("current_team", "CIC ë´„ë‚ ")

# ëŒ€í™” ID ì´ˆê¸°í™”
if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = None

# ëŒ€í™” ê¸°ë¡ expander
with st.expander("ğŸ“š ëŒ€í™” ê¸°ë¡", expanded=False):
    conversations = list_conversations(current_team, limit=10)

    if conversations:
        st.caption(f"ìµœê·¼ {len(conversations)}ê°œ ëŒ€í™”")

        for conv in conversations:
            conv_id = conv["conversation_id"]
            preview = conv["preview"]
            msg_count = conv["message_count"]
            created = conv["created_at"][:16]  # YYYY-MM-DD HH:MM

            col1, col2 = st.columns([4, 1])
            with col1:
                if st.button(
                    f"ğŸ’¬ {preview} ({msg_count}ê°œ)",
                    key=f"load_{conv_id}",
                    help=f"ìƒì„±: {created}",
                    use_container_width=True
                ):
                    # ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
                    messages, metadata = load_conversation(current_team, conv_id)
                    if messages:
                        st.session_state.unified_messages = messages
                        st.session_state.current_conversation_id = conv_id
                        st.toast(f"âœ… ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ ({msg_count}ê°œ ë©”ì‹œì§€)")
                        st.rerun()
            with col2:
                st.caption(f"{created[5:]}")  # MM-DD HH:MM
    else:
        st.info("ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

st.markdown("---")

# ========================================
# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
# ========================================
initialize_agent()

avatar_image = get_avatar_image()
user_avatar_image = get_user_avatar_image()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "unified_messages" not in st.session_state:
    st.session_state.unified_messages = []
if "unified_files" not in st.session_state:
    st.session_state.unified_files = []
if "processed_upload_keys" not in st.session_state:
    st.session_state.processed_upload_keys = []
if "uploader_key_seed" not in st.session_state:
    st.session_state.uploader_key_seed = 0
if "report_panel_enabled" not in st.session_state:
    st.session_state.report_panel_enabled = False
if "unified_mode" not in st.session_state:
    st.session_state.unified_mode = "unified"
if "report_preparse_results" not in st.session_state:
    st.session_state.report_preparse_results = {}
if "report_preparse_status" not in st.session_state:
    st.session_state.report_preparse_status = "idle"
if "report_preparse_at" not in st.session_state:
    st.session_state.report_preparse_at = None
if "report_preparse_summary" not in st.session_state:
    st.session_state.report_preparse_summary = []
if "report_preparse_progress" not in st.session_state:
    st.session_state.report_preparse_progress = 0.0
if "report_preparse_current" not in st.session_state:
    st.session_state.report_preparse_current = ""
if "report_preparse_total" not in st.session_state:
    st.session_state.report_preparse_total = 0
if "report_preparse_log" not in st.session_state:
    st.session_state.report_preparse_log = []
if "report_panel_uploader_seed" not in st.session_state:
    st.session_state.report_panel_uploader_seed = 0
if "report_preparse_max_pages" not in st.session_state:
    st.session_state.report_preparse_max_pages = 30
if "report_preparse_market_evidence" not in st.session_state:
    st.session_state.report_preparse_market_evidence = True
if "report_preparse_fast_mode" not in st.session_state:
    st.session_state.report_preparse_fast_mode = False
if "report_preparse_mode" not in st.session_state:
    st.session_state.report_preparse_mode = "ì •í™•ë„ ìš°ì„  (Vision)"
if "report_preparse_min_text_chars" not in st.session_state:
    st.session_state.report_preparse_min_text_chars = 200
if "report_preparse_max_ocr_pages" not in st.session_state:
    st.session_state.report_preparse_max_ocr_pages = 8
if "report_preparse_stage1_md" not in st.session_state:
    st.session_state.report_preparse_stage1_md = ""
if "report_preparse_stage2_md" not in st.session_state:
    st.session_state.report_preparse_stage2_md = ""
if "report_md_imported_at" not in st.session_state:
    st.session_state.report_md_imported_at = None
if "report_evidence_pack_md" not in st.session_state:
    st.session_state.report_evidence_pack_md = ""
if "report_evidence_pack_at" not in st.session_state:
    st.session_state.report_evidence_pack_at = None
if "report_evidence_pack_status" not in st.session_state:
    st.session_state.report_evidence_pack_status = "idle"
if "report_evidence_pack_company" not in st.session_state:
    st.session_state.report_evidence_pack_company = ""
if "report_evidence_pack_raw" not in st.session_state:
    st.session_state.report_evidence_pack_raw = ""
if "report_evidence_pack_raw_at" not in st.session_state:
    st.session_state.report_evidence_pack_raw_at = None
if "report_evidence_pack_raw_status" not in st.session_state:
    st.session_state.report_evidence_pack_raw_status = "idle"

if st.session_state.get("report_panel_enabled"):
    st.markdown(
        """
        <style>
        .main .block-container { max-width: 1400px; }
        </style>
        """,
        unsafe_allow_html=True,
    )


def _init_report_chapters() -> list:
    outline = st.session_state.get("report_outline") or []
    chapter_order = [item for item in outline if re.match(r'^[IVX]+\\.', item)]
    if not chapter_order:
        chapter_order = [
            "I. íˆ¬ì ê°œìš”",
            "II. ê¸°ì—… í˜„í™©",
            "III. ì‹œì¥ ë¶„ì„",
            "IV. ì‚¬ì—… ë¶„ì„",
            "V. íˆ¬ì ì í•©ì„± ë° ì„íŒ©íŠ¸",
            "VI. ìˆ˜ìµì„±/Valuation",
            "VII. ì„íŒ©íŠ¸ ë¦¬ìŠ¤í¬",
            "VIII. ì¢…í•© ê²°ë¡ ",
        ]
    if not st.session_state.get("report_chapter_order"):
        st.session_state.report_chapter_order = chapter_order
    return st.session_state.report_chapter_order


def _compose_full_draft(chapters: dict, order: list) -> str:
    blocks = []
    for key in order:
        content = (chapters or {}).get(key)
        if content:
            blocks.append(content.strip())
    return "\n\n".join(blocks).strip()


def _save_current_chapter(mark_done: bool = False) -> None:
    chapter_order = st.session_state.get("report_chapter_order") or []
    idx = st.session_state.get("report_chapter_index", 0)
    if not chapter_order:
        return
    idx = max(0, min(idx, len(chapter_order) - 1))
    current = chapter_order[idx]
    current_text = st.session_state.get("report_edit_buffer", "").strip()
    if current_text:
        st.session_state.report_chapters[current] = current_text
    if mark_done:
        st.session_state.report_chapter_status[current] = "done"
    else:
        st.session_state.report_chapter_status.setdefault(current, "draft")
    st.session_state.report_draft_content = _compose_full_draft(
        st.session_state.report_chapters,
        chapter_order,
    )


def _build_preparse_summary(results: dict) -> list:
    summary = []
    for path, info in (results or {}).items():
        entry = {
            "file": Path(path).name,
            "type": "",
            "status": "ì‹¤íŒ¨",
            "detail": "",
        }
        if "pdf" in info:
            pdf_result = info.get("pdf", {})
            entry["type"] = "PDF"
            if pdf_result.get("success"):
                entry["status"] = "ì„±ê³µ"
                pages = pdf_result.get("pages_read")
                total_pages = pdf_result.get("total_pages")
                method = pdf_result.get("processing_method", "")
                entry["detail"] = f"{pages}/{total_pages}p Â· {method}"
            else:
                entry["detail"] = pdf_result.get("error", "PDF íŒŒì‹± ì‹¤íŒ¨")
            evidence = info.get("market_evidence", {})
            if isinstance(evidence, dict) and evidence.get("success"):
                entry["detail"] += f" Â· ì‹œì¥ê·¼ê±° {evidence.get('evidence_count', 0)}ê±´"
        elif "excel" in info:
            excel_result = info.get("excel", {})
            entry["type"] = "Excel"
            if excel_result.get("success"):
                entry["status"] = "ì„±ê³µ"
                entry["detail"] = f"ì‹œíŠ¸ {excel_result.get('total_sheets', 0)}ê°œ"
            else:
                entry["detail"] = excel_result.get("error", "ì—‘ì…€ íŒŒì‹± ì‹¤íŒ¨")
        elif "docx" in info:
            docx_result = info.get("docx", {})
            entry["type"] = "DOCX"
            if docx_result.get("success"):
                entry["status"] = "ì„±ê³µ"
                entry["detail"] = f"ë¬¸ë‹¨ {docx_result.get('parsed_paragraphs', 0)}ê°œ"
            else:
                entry["detail"] = docx_result.get("error", "DOCX íŒŒì‹± ì‹¤íŒ¨")
        else:
            entry["detail"] = info.get("error", "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼")
        summary.append(entry)
    return summary


def _build_preparse_context(summary: list) -> Optional[str]:
    if not summary:
        return None
    lines = ["ì‚¬ì „ íŒŒì‹± ì™„ë£Œ (ìºì‹œ ì‚¬ìš© ê°€ëŠ¥):"]
    for item in summary:
        lines.append(
            f"- {item.get('file')} [{item.get('type')}] {item.get('status')} Â· {item.get('detail')}"
        )
    return "\n".join(lines)


def _build_preparse_summary_block(summary: list) -> str:
    if not summary:
        return "- (íŒŒì‹± ìš”ì•½ ì—†ìŒ)"
    lines = []
    for item in summary:
        lines.append(
            f"- file: {item.get('file')} | type: {item.get('type')} | status: {item.get('status')} | detail: {item.get('detail')}"
        )
    return "\n".join(lines)


def _condense_stage1_for_extract(stage1_md: str, max_chars: int = 60000) -> str:
    if not stage1_md:
        return ""
    if len(stage1_md) <= max_chars:
        return stage1_md
    keywords = [
        "ë§¤ì¶œ", "ì˜ì—…", "ìˆœì´ìµ", "ìì‚°", "ë¶€ì±„", "ìë³¸", "í˜„ê¸ˆ", "íˆ¬ì", "ì£¼ì£¼", "ì§€ë¶„",
        "ì„¤ë¦½", "ëŒ€í‘œ", "ë²•ì¸", "ì‚¬ì—…ì", "ì¸ì¦", "íŠ¹í—ˆ", "ê³ ê°", "ê³„ì•½", "ì‹œì¥",
        "TAM", "SAM", "SOM", "ì„±ì¥", "ì¬ë¬´", "IR", "valuation", "cap", "cap table",
    ]
    lines = []
    for line in stage1_md.splitlines():
        if any(k in line for k in keywords) or re.search(r"\\d", line):
            lines.append(line)
    condensed = "\n".join(lines).strip()
    if len(condensed) < 1000:
        half = max_chars // 2
        head = stage1_md[:half]
        tail = stage1_md[-half:]
        condensed = (head + "\n...\n" + tail).strip()
    return condensed[:max_chars]


def _derive_company_label(files: list) -> str:
    if not files:
        return "unknown"
    name = Path(files[0]).stem
    name = re.sub(r"^[0-9a-f]{6,}_", "", name)
    name = re.sub(r"[_\-]+", " ", name).strip()
    return name or "unknown"


def _format_financial_tables_md(financial_tables: dict, source_file: str = "") -> str:
    """financial_tables ë”•ì…”ë„ˆë¦¬ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    if not financial_tables:
        return ""

    lines = []
    source_prefix = f"[{source_file}] " if source_file else ""

    # ì†ìµê³„ì‚°ì„œ
    is_data = financial_tables.get("income_statement", {})
    if is_data.get("found"):
        lines.append(f"#### {source_prefix}ì†ìµê³„ì‚°ì„œ (p.{is_data.get('page', '?')})")
        unit = is_data.get("unit", "")
        years = is_data.get("years", [])
        metrics = is_data.get("metrics", {})
        if years and metrics:
            header = "| í•­ëª© | " + " | ".join(str(y) for y in years) + " |"
            sep = "| --- |" + " --- |" * len(years)
            lines.append(header)
            lines.append(sep)
            metric_names = {
                "revenue": "ë§¤ì¶œì•¡",
                "gross_profit": "ë§¤ì¶œì´ì´ìµ",
                "operating_income": "ì˜ì—…ì´ìµ",
                "ebitda": "EBITDA",
                "net_income": "ë‹¹ê¸°ìˆœì´ìµ",
            }
            for key, label in metric_names.items():
                vals = metrics.get(key, [])
                if vals:
                    row = f"| {label} ({unit}) | " + " | ".join(str(v) if v is not None else "-" for v in vals) + " |"
                    lines.append(row)
        lines.append("")

    # ì¬ë¬´ìƒíƒœí‘œ
    bs_data = financial_tables.get("balance_sheet", {})
    if bs_data.get("found"):
        lines.append(f"#### {source_prefix}ì¬ë¬´ìƒíƒœí‘œ (p.{bs_data.get('page', '?')})")
        unit = bs_data.get("unit", "")
        years = bs_data.get("years", [])
        metrics = bs_data.get("metrics", {})
        if years and metrics:
            header = "| í•­ëª© | " + " | ".join(str(y) for y in years) + " |"
            sep = "| --- |" + " --- |" * len(years)
            lines.append(header)
            lines.append(sep)
            metric_names = {
                "total_assets": "ì´ìì‚°",
                "total_liabilities": "ì´ë¶€ì±„",
                "total_equity": "ì´ìë³¸",
                "cash": "í˜„ê¸ˆì„±ìì‚°",
            }
            for key, label in metric_names.items():
                vals = metrics.get(key, [])
                if vals:
                    row = f"| {label} ({unit}) | " + " | ".join(str(v) if v is not None else "-" for v in vals) + " |"
                    lines.append(row)
        lines.append("")

    # í˜„ê¸ˆíë¦„í‘œ
    cf_data = financial_tables.get("cash_flow", {})
    if cf_data.get("found"):
        lines.append(f"#### {source_prefix}í˜„ê¸ˆíë¦„í‘œ (p.{cf_data.get('page', '?')})")
        unit = cf_data.get("unit", "")
        years = cf_data.get("years", [])
        metrics = cf_data.get("metrics", {})
        if years and metrics:
            header = "| í•­ëª© | " + " | ".join(str(y) for y in years) + " |"
            sep = "| --- |" + " --- |" * len(years)
            lines.append(header)
            lines.append(sep)
            metric_names = {
                "operating_cf": "ì˜ì—…CF",
                "investing_cf": "íˆ¬ìCF",
                "financing_cf": "ì¬ë¬´CF",
                "fcf": "FCF",
            }
            for key, label in metric_names.items():
                vals = metrics.get(key, [])
                if vals:
                    row = f"| {label} ({unit}) | " + " | ".join(str(v) if v is not None else "-" for v in vals) + " |"
                    lines.append(row)
        lines.append("")

    # Cap Table
    cap_data = financial_tables.get("cap_table", {})
    if cap_data.get("found"):
        lines.append(f"#### {source_prefix}Cap Table (p.{cap_data.get('page', '?')})")
        shareholders = cap_data.get("shareholders", [])
        if shareholders:
            lines.append("| ì£¼ì£¼ëª… | ì§€ë¶„ìœ¨ | ì£¼ì‹ìˆ˜ |")
            lines.append("| --- | --- | --- |")
            for sh in shareholders:
                name = sh.get("name", "")
                pct = sh.get("ownership_pct", sh.get("percentage", ""))
                shares = sh.get("shares", "")
                lines.append(f"| {name} | {pct} | {shares} |")
        total_shares = cap_data.get("total_shares")
        if total_shares:
            lines.append(f"\nì´ë°œí–‰ì£¼ì‹ìˆ˜: {total_shares:,}" if isinstance(total_shares, (int, float)) else f"\nì´ë°œí–‰ì£¼ì‹ìˆ˜: {total_shares}")
        lines.append("")

    return "\n".join(lines)


def _format_investment_terms_md(inv_terms: dict, source_file: str = "") -> str:
    """íˆ¬ìì¡°ê±´ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    if not inv_terms or not inv_terms.get("found"):
        return ""

    source_prefix = f"[{source_file}] " if source_file else ""
    lines = [f"#### {source_prefix}íˆ¬ìì¡°ê±´ (p.{inv_terms.get('page', '?')})"]

    field_names = {
        "investment_amount": "íˆ¬ìê¸ˆì•¡",
        "pre_money": "Pre-money ë°¸ë¥˜",
        "post_money": "Post-money ë°¸ë¥˜",
        "price_per_share": "ì£¼ë‹¹ íˆ¬ìë‹¨ê°€",
        "shares_acquired": "ì·¨ë“ ì£¼ì‹ìˆ˜",
        "ownership_pct": "ì·¨ë“ ì§€ë¶„ìœ¨",
        "investment_type": "íˆ¬ì êµ¬ì¡°",
        "investment_round": "íˆ¬ì ë¼ìš´ë“œ",
    }

    for key, label in field_names.items():
        val = inv_terms.get(key)
        if val:
            lines.append(f"- {label}: {val}")

    return "\n".join(lines) + "\n"


def _build_stage1_markdown(results: dict) -> str:
    blocks = []
    appendix_blocks = []

    for path, info in (results or {}).items():
        title = Path(path).name
        blocks.append(f"### {title}")
        if "pdf" in info:
            pdf_result = info.get("pdf", {})
            content = pdf_result.get("content") or ""
            blocks.append(content if content else "_(PDF í…ìŠ¤íŠ¸ ì—†ìŒ)_")

            # êµ¬ì¡°í™”ëœ ì¬ë¬´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ Appendixì— ì¶”ê°€
            financial_tables = pdf_result.get("financial_tables", {})
            if financial_tables:
                ft_md = _format_financial_tables_md(financial_tables, title)
                if ft_md.strip():
                    appendix_blocks.append(ft_md)

            # íˆ¬ìì¡°ê±´ ë°ì´í„°
            inv_terms = pdf_result.get("investment_terms", {})
            if inv_terms and inv_terms.get("found"):
                inv_md = _format_investment_terms_md(inv_terms, title)
                if inv_md.strip():
                    appendix_blocks.append(inv_md)

        elif "excel" in info:
            content = info.get("excel", {}).get("content") or ""
            blocks.append(content if content else "_(ì—‘ì…€ í…ìŠ¤íŠ¸ ì—†ìŒ)_")
        elif "docx" in info:
            content = info.get("docx", {}).get("content") or ""
            blocks.append(content if content else "_(DOCX í…ìŠ¤íŠ¸ ì—†ìŒ)_")
        else:
            blocks.append("_ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹_")
        blocks.append("")

    # Appendix: êµ¬ì¡°í™”ëœ ì¬ë¬´ ë°ì´í„°
    if appendix_blocks:
        blocks.append("\n---\n## Appendix: ìë™ ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„°\n")
        blocks.append("ì•„ë˜ ë°ì´í„°ëŠ” PDFì—ì„œ ìë™ ì¶”ì¶œëœ êµ¬ì¡°í™”ëœ ì¬ë¬´ì •ë³´ì…ë‹ˆë‹¤.\n")
        blocks.extend(appendix_blocks)

    return "\n".join(blocks).strip()


def _build_preparse_md() -> str:
    summary = st.session_state.get("report_preparse_summary", [])
    results = st.session_state.get("report_preparse_results", {})
    stage1_md = st.session_state.get("report_preparse_stage1_md") or _build_stage1_markdown(results)
    stage2_md = st.session_state.get("report_preparse_stage2_md") or "N/A"
    files = st.session_state.get("unified_files", [])
    label = _derive_company_label(files)
    created_at = datetime.now().isoformat()
    lines = [
        "# MerryParse Export",
        f"- created_at: {created_at}",
        f"- source_files: {[Path(f).name for f in files]}",
        f"- ocr_mode: {st.session_state.get('report_preparse_mode')}",
        f"- max_pages: {st.session_state.get('report_preparse_max_pages')}",
        f"- market_evidence: {st.session_state.get('report_preparse_market_evidence')}",
        "",
        "## Stage1 (Raw Markdown)",
        stage1_md if stage1_md else "N/A",
        "",
        "## Stage2 (Refined Markdown)",
        stage2_md if stage2_md else "N/A",
        "",
        "## Summary",
    ]
    for item in summary:
        lines.append(
            f"- file: {item.get('file')} | status: {item.get('status')} | detail: {item.get('detail')}"
        )
    return "\n".join(lines), label


def _parse_md_sections(md_text: str) -> dict:
    sections = {"stage1": "", "stage2": "", "summary": []}
    current = None
    for line in md_text.splitlines():
        if line.strip().startswith("## Stage1"):
            current = "stage1"
            continue
        if line.strip().startswith("## Stage2"):
            current = "stage2"
            continue
        if line.strip().startswith("## Summary"):
            current = "summary"
            continue
        if current == "summary":
            if line.strip().startswith("- file:"):
                parts = line.split("|")
                entry = {"file": "", "status": "", "detail": ""}
                if parts:
                    entry["file"] = parts[0].replace("- file:", "").strip()
                if len(parts) > 1:
                    entry["status"] = parts[1].replace("status:", "").strip()
                if len(parts) > 2:
                    entry["detail"] = parts[2].replace("detail:", "").strip()
                sections["summary"].append(entry)
        elif current in ["stage1", "stage2"]:
            sections[current] += line + "\n"
    for key in ["stage1", "stage2"]:
        sections[key] = sections[key].strip()
    return sections


def _restore_from_md(md_text: str) -> None:
    if md_text.lstrip().startswith("# Investment Review Evidence Pack"):
        st.session_state.report_evidence_pack_md = md_text
        st.session_state.report_evidence_pack_at = datetime.now().isoformat()
        st.session_state.report_md_imported_at = datetime.now().isoformat()
        company = ""
        for line in md_text.splitlines()[:20]:
            if line.strip().startswith("- company:"):
                company = line.split(":", 1)[1].strip()
                break
        st.session_state.report_evidence_pack_company = company
        return
    parsed = _parse_md_sections(md_text)
    st.session_state.report_preparse_stage1_md = parsed.get("stage1", "")
    st.session_state.report_preparse_stage2_md = parsed.get("stage2", "")
    st.session_state.report_preparse_summary = parsed.get("summary", [])
    st.session_state.report_preparse_at = datetime.now().isoformat()
    st.session_state.report_md_imported_at = datetime.now().isoformat()


def _collect_market_evidence(results: dict, max_items: int = 30) -> list:
    items = []
    for path, info in (results or {}).items():
        evidence = info.get("market_evidence", {})
        if not isinstance(evidence, dict):
            continue
        for entry in evidence.get("evidence", [])[:max_items]:
            items.append({
                "file": Path(path).name,
                "page": entry.get("page"),
                "text": entry.get("text"),
                "numbers": entry.get("numbers", []),
            })
            if len(items) >= max_items:
                return items
    return items


def _collect_structured_financial_data(results: dict) -> str:
    """íŒŒì‹± ê²°ê³¼ì—ì„œ êµ¬ì¡°í™”ëœ ì¬ë¬´ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ìˆ˜ì§‘"""
    blocks = []

    for path, info in (results or {}).items():
        filename = Path(path).name
        if "pdf" not in info:
            continue

        pdf_result = info.get("pdf", {})
        financial_tables = pdf_result.get("financial_tables", {})
        investment_terms = pdf_result.get("investment_terms", {})

        # ì¬ë¬´ì œí‘œ ë°ì´í„°
        if financial_tables:
            ft_md = _format_financial_tables_md(financial_tables, filename)
            if ft_md.strip():
                blocks.append(ft_md)

        # íˆ¬ìì¡°ê±´ ë°ì´í„°
        if investment_terms and investment_terms.get("found"):
            inv_md = _format_investment_terms_md(investment_terms, filename)
            if inv_md.strip():
                blocks.append(inv_md)

    if not blocks:
        return "- (ìë™ ì¶”ì¶œëœ êµ¬ì¡°í™” ë°ì´í„° ì—†ìŒ)"

    return "\n\n".join(blocks)


def _extract_evidence_pack_quality(md_text: str) -> dict:
    lines = [line.strip() for line in (md_text or "").splitlines()]
    evidence_count = sum(1 for line in lines if line.startswith("- [ê·¼ê±°"))
    has_unknown = any("íŒë‹¨ ìœ ë³´" in line for line in lines)
    return {
        "evidence_count": evidence_count,
        "has_unknown": has_unknown,
    }


def _is_evidence_pack_stale() -> bool:
    pack_at = st.session_state.get("report_evidence_pack_at")
    preparse_at = st.session_state.get("report_preparse_at")
    if not pack_at or not preparse_at:
        return False
    try:
        return pack_at < preparse_at
    except Exception:
        return False


def _build_evidence_pack_extract_prompt(stage1_md: str, evidence_items: list, preparse_summary: str, structured_financial: str = "") -> str:
    company = st.session_state.get("report_evidence_pack_company") or "unknown"
    source_files = [Path(f).name for f in st.session_state.get("unified_files", [])]
    created_at = datetime.now().isoformat()
    evidence_lines = []
    for item in evidence_items:
        page = item.get("page")
        page_text = f"p.{page}" if page else "p.?"
        text = (item.get("text") or "").strip()
        numbers = item.get("numbers") or []
        number_str = ", ".join(numbers) if numbers else ""
        evidence_lines.append(
            f"- [{item.get('file')}] {page_text}: {text} {number_str}".strip()
        )

    evidence_block = "\n".join(evidence_lines) if evidence_lines else "- (ê·¼ê±° ì—†ìŒ)"
    structured_block = structured_financial if structured_financial else "- (ìë™ ì¶”ì¶œëœ êµ¬ì¡°í™” ë°ì´í„° ì—†ìŒ)"

    return textwrap.dedent(
        f"""
        ë‹¹ì‹ ì€ ë¬¸ì„œì—ì„œ ì‚¬ì‹¤/ìˆ˜ì¹˜ë§Œ ë½‘ì•„ë‚´ëŠ” Extractorì…ë‹ˆë‹¤.
        ì•„ë˜ ìë£Œë¥¼ ì½ê³  **JSONë§Œ** ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª… ê¸ˆì§€.

        **ì¤‘ìš”: [ìë™ ì¶”ì¶œëœ êµ¬ì¡°í™” ì¬ë¬´ ë°ì´í„°] ì„¹ì…˜ì— ì´ë¯¸ ì†ìµê³„ì‚°ì„œ/ì¬ë¬´ìƒíƒœí‘œ/Cap Table ë“±ì´ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.**
        **ì´ ë°ì´í„°ë¥¼ numbersì— ê·¸ëŒ€ë¡œ ì˜®ê¸°ê³ , ì¶”ê°€ë¡œ í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬í•œ ì •ë³´ë§Œ ë³´ì¶©í•˜ì„¸ìš”.**
        **ìë™ ì¶”ì¶œ ë°ì´í„°ê°€ ìˆëŠ” í•­ëª©ì€ [ì¶”ì •]ì´ ì•„ë‹ˆë¼ ì‹¤ì œ Sourceë¥¼ ëª…ì‹œí•˜ì„¸ìš”.**

        JSON ìŠ¤í‚¤ë§ˆ:
        {{
          "company": "{company}",
          "source_files": {source_files},
          "facts": [{{"chapter": "I. íˆ¬ì ê°œìš”", "text": "...", "source": "íŒŒì¼ëª… p.x"}}],
          "numbers": [{{"chapter": "VI. ìˆ˜ìµì„±/Valuation", "metric": "ë§¤ì¶œ", "value": "1,234", "unit": "ë°±ë§Œì›", "period": "2024", "source": "íŒŒì¼ëª… p.x"}}],
          "financial_tables": {{
            "income_statement": {{"years": [...], "revenue": [...], "operating_income": [...], "net_income": [...], "unit": "...", "source": "íŒŒì¼ëª… p.x"}},
            "balance_sheet": {{"years": [...], "total_assets": [...], "total_liabilities": [...], "total_equity": [...], "unit": "...", "source": "íŒŒì¼ëª… p.x"}},
            "cap_table": {{"shareholders": [{{"name": "...", "ownership_pct": "...", "shares": ...}}], "total_shares": ..., "source": "íŒŒì¼ëª… p.x"}},
            "investment_terms": {{"amount": "...", "pre_money": "...", "price_per_share": "...", "source": "íŒŒì¼ëª… p.x"}}
          }},
          "entities": {{"organizations": [], "people": [], "products": [], "certifications": [], "competitors": []}},
          "missing": [{{"chapter": "III. ì‹œì¥ ë¶„ì„", "items": ["TAM/SAM/SOM"]}}]
        }}

        ê·œì¹™:
        - **ìë™ ì¶”ì¶œëœ êµ¬ì¡°í™” ë°ì´í„°ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©** (ì´ë¯¸ íŒŒì‹± ì™„ë£Œëœ ì •í™•í•œ ë°ì´í„°)
        - Fact/NumberëŠ” ë°˜ë“œì‹œ Source í¬í•¨ (íŒŒì¼ëª… p.í˜ì´ì§€ë²ˆí˜¸)
        - ìë™ ì¶”ì¶œ ë°ì´í„°ì— ì—†ëŠ” í•­ëª©ë§Œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ê°€ ì¶”ì¶œ
        - ì¶”ì •ì€ textì— [ì¶”ì •] í‘œê¸° (ìë™ ì¶”ì¶œ ë°ì´í„°ëŠ” ì¶”ì • ì•„ë‹˜)
        - ìˆ«ìëŠ” ë‹¨ìœ„/ê¸°ê°„ í¬í•¨
        - ìë£Œê°€ ì—†ìœ¼ë©´ missingì— ê¸°ë¡
        - JSON ì´ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€

        [íŒŒì‹± ìš”ì•½]
        {preparse_summary}

        [ìë™ ì¶”ì¶œëœ êµ¬ì¡°í™” ì¬ë¬´ ë°ì´í„°] (ìµœìš°ì„  ì‚¬ìš©)
        {structured_block}

        [Stage1 Markdown]
        {stage1_md}

        [Market Evidence]
        {evidence_block}
        """
    ).strip()


def _build_evidence_pack_format_prompt(extraction_json: str, preparse_summary: str) -> str:
    company = st.session_state.get("report_evidence_pack_company") or "unknown"
    source_files = [Path(f).name for f in st.session_state.get("unified_files", [])]
    created_at = datetime.now().isoformat()
    return textwrap.dedent(
        f"""
        ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ VC ì‹¬ì‚¬ì—­ì…ë‹ˆë‹¤. ì•„ë˜ ì¶”ì¶œ JSONì„ ë°”íƒ•ìœ¼ë¡œ **Evidence Pack MD (ì‹¬ì‚¬ì—­ì´ ë³´ì™„ ê°€ëŠ¥í•œ ì¶”ì¶œë¬¼)**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ì´ ë¬¸ì„œëŠ” **GPT-2 ìˆ˜ì¤€ ëª¨ë¸ë„ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì¶”ì¶œë¬¼**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

        ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒ í…œí”Œë¦¿ì„ ë”°ë¥´ì„¸ìš”:

        # Investment Review Evidence Pack
        - company: {company}
        - created_at: {created_at}
        - source_files: {source_files}

        ## 0. íŒŒì‹± ìš”ì•½
        {preparse_summary}

        ## 1. í•µì‹¬ ì •ë³´ ìš”ì•½ (One-Page)
        - ê¸°ì—…/ì œí’ˆ í•œì¤„ ìš”ì•½:
        - íƒ€ê²Ÿ ì‹œì¥/ê³ ê°:
        - ìˆ˜ìµ ëª¨ë¸:
        - í˜„ì¬ ë‹¨ê³„(ì‹œë“œ/Pre-A/Series A ë“±):
        - í•µì‹¬ ìˆ˜ì¹˜(ë§¤ì¶œ/ì†ìµ/ìë³¸/ë¶€ì±„ ë“±):

        ## 2. ì±•í„°ë³„ ê·¼ê±° ë§µ (Facts/Numbers)
        ### I. íˆ¬ì ê°œìš”
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### II. ê¸°ì—… í˜„í™©
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### III. ì‹œì¥ ë¶„ì„
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### IV. ì‚¬ì—… ë¶„ì„
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### V. íˆ¬ì ì í•©ì„± ë° ì„íŒ©íŠ¸
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### VI. ìˆ˜ìµì„±/Valuation
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### VII. ì„íŒ©íŠ¸ ë¦¬ìŠ¤í¬
        #### Facts
        - Fact: ... | Source: ...
        #### Numbers
        | Metric | Value | Unit | Period | Source |
        | --- | --- | --- | --- | --- |
        #### Missing
        - ...

        ### VIII. ì¢…í•© ê²°ë¡ 
        #### Facts
        - Fact: ... | Source: ...
        #### Missing
        - ...

        ## 3. ì—”í‹°í‹°/í‚¤ì›Œë“œ
        - Organizations:
        - People:
        - Products/Services:
        - Certifications/Regulatory:
        - Competitors:

        ## 4. ì¬ë¬´/í‘œ ì¶”ì¶œ (ìë™ ì¶”ì¶œ ë°ì´í„° ê¸°ë°˜)
        **âš ï¸ ì¤‘ìš”: Extraction JSONì˜ financial_tablesì— ìë™ ì¶”ì¶œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. [ì¶”ì •] í‘œê¸° ê¸ˆì§€.**

        ### 4.1 ì†ìµê³„ì‚°ì„œ
        | Year | Revenue | Gross Profit | Operating Income | Net Income | Unit | Source |
        | --- | --- | --- | --- | --- | --- | --- |
        (financial_tables.income_statement ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ í¼ì³ì„œ ì‘ì„±)

        ### 4.2 ì¬ë¬´ìƒíƒœí‘œ
        | Year | Total Assets | Total Liabilities | Total Equity | Cash | Unit | Source |
        | --- | --- | --- | --- | --- | --- | --- |
        (financial_tables.balance_sheet ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ í¼ì³ì„œ ì‘ì„±)

        ### 4.3 í˜„ê¸ˆíë¦„
        | Year | Operating CF | Investing CF | Financing CF | FCF | Unit | Source |
        | --- | --- | --- | --- | --- | --- |
        (financial_tables.cash_flow ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‘ì„±)

        ### 4.4 Cap Table
        | ì£¼ì£¼ëª… | ì§€ë¶„ìœ¨ | ì£¼ì‹ìˆ˜ |
        | --- | --- | --- |
        (financial_tables.cap_table.shareholders ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‘ì„±)
        ì´ë°œí–‰ì£¼ì‹ìˆ˜: (financial_tables.cap_table.total_shares)

        ### 4.5 íˆ¬ìì¡°ê±´
        (financial_tables.investment_terms ë°ì´í„°ë¥¼ í•­ëª©ë³„ë¡œ ì‘ì„±)
        - íˆ¬ìê¸ˆì•¡:
        - Pre-money:
        - ì£¼ë‹¹ê°€ê²©:
        - ì·¨ë“ì§€ë¶„:

        ## 5. HF ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì‚¬ëŒ ê²€í† ìš©)
        - [ ] íˆ¬ì ì¡°ê±´(ê¸ˆì•¡/ë°¸ë¥˜/ì§€ë¶„ìœ¨) ì›ë¬¸ í™•ì¸
        - [ ] í•µì‹¬ ì œí’ˆ/ì„œë¹„ìŠ¤ ê¸°ëŠ¥ ê²€ì¦
        - [ ] ì£¼ìš” ê³ ê°/ë§¤ì¶œì²˜ ê²€ì¦
        - [ ] ì¬ë¬´ì œí‘œ ìˆ˜ì¹˜ ëŒ€ì¡°
        - [ ] ë²•ì  ë¦¬ìŠ¤í¬(ë“±ê¸°ë¶€ ë§ì†Œì‚¬í•­) í™•ì¸

        ## 6. Machine-Readable Summary (YAML)
        ```yaml
        company: {company}
        industry: unknown
        products: []
        customers: []
        business_model: unknown
        stage: unknown
        financials:
          revenue: {{}}
          operating_income: {{}}
          net_income: {{}}
          assets: {{}}
          liabilities: {{}}
        certifications: []
        risks: []
        ```

        ê·œì¹™:
        - **ğŸš¨ ìµœìš°ì„ : financial_tablesì— ìë™ ì¶”ì¶œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì‚¬ìš©. [ì¶”ì •] í‘œê¸° ëŒ€ì‹  ì‹¤ì œ Source(íŒŒì¼ëª… p.í˜ì´ì§€) ëª…ì‹œ**
        - ë°˜ë“œì‹œ ê° ì±•í„°ë³„ë¡œ Facts/Numbers/Missingì„ í¬í•¨
        - ê·¼ê±° ë¬¸í•­ì€ ê°€ëŠ¥í•˜ë©´ 5ê°œ, ë¶€ì¡±í•˜ë©´ 2~3ê°œë¼ë„ ì‘ì„±
        - ìë£Œê°€ ë¶€ì¡±í•˜ë©´ "íŒë‹¨ ìœ ë³´(ê·¼ê±° ë¶€ì¡±)"ìœ¼ë¡œ ëª…ì‹œí•˜ë˜, íŒŒì¼ëª…/ë©”íƒ€ì—ì„œ í•©ë¦¬ì  ì¶”ì •ì´ ê°€ëŠ¥í•œ ê²½ìš° [ì¶”ì •]ìœ¼ë¡œ í‘œê¸°
        - ëª¨ë“  Fact/NumberëŠ” **Source**ë¥¼ í¬í•¨ (ì—†ìœ¼ë©´ "Source: Evidence Pack MD"ë¡œ í‘œì‹œ)
        - company/source_files/created_at ê°’ì„ ì„ì˜ë¡œ ë³€ê²½í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì¶œë ¥
        - ë¶ˆí•„ìš”í•œ ì„œë¡ /ì„¤ëª… ì—†ì´ MDë§Œ ì¶œë ¥
        - **ì„¹ì…˜ 4ì˜ ì¬ë¬´ í…Œì´ë¸”ì€ financial_tables ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì˜®ê²¨ ì‘ì„± (ë¹„ì–´ìˆì§€ ì•Šê²Œ)**

        [Extraction JSON]
        {extraction_json}
        """
    ).strip()

def _preparse_report_files_batch(
    max_pages: int,
    include_market_evidence: bool,
) -> None:
    """ëª¨ë“  PDFë¥¼ í•œ ë²ˆì— í•©ì³ì„œ ë‹¨ì¼ API í˜¸ì¶œë¡œ ì²˜ë¦¬ (íš¨ìœ¨ì )"""
    st.session_state.report_preparse_status = "running"
    st.session_state.report_preparse_progress = 0.0
    st.session_state.report_preparse_current = ""
    st.session_state.report_preparse_log = []

    files = list(st.session_state.get("unified_files", []))
    missing_files = [f for f in files if not Path(f).exists()]
    if missing_files:
        st.warning("ì¼ë¶€ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        files = [f for f in files if Path(f).exists()]
        st.session_state.unified_files = files
    if not files:
        st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.session_state.report_preparse_status = "idle"
        return

    st.session_state.report_preparse_total = len(files)
    progress = st.progress(0.0)
    status = st.empty()

    # PDFì™€ ê¸°íƒ€ íŒŒì¼ ë¶„ë¦¬
    pdf_files = [f for f in files if Path(f).suffix.lower() == ".pdf"]
    other_files = [f for f in files if Path(f).suffix.lower() != ".pdf"]

    results = {}

    # 1. ëª¨ë“  PDFë¥¼ í•œ ë²ˆì— ë°°ì¹˜ ì²˜ë¦¬
    if pdf_files:
        status.markdown(
            f"<div class='report-preparse-status'>ğŸ“¥ {len(pdf_files)}ê°œ PDF ì¼ê´„ ë¶„ì„ ì¤‘...</div>",
            unsafe_allow_html=True,
        )
        st.session_state.report_preparse_log.append(f"PDF {len(pdf_files)}ê°œ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘")
        st.session_state.report_preparse_current = f"PDF {len(pdf_files)}ê°œ"

        def progress_cb(event):
            msg = event.get("content", "")
            st.session_state.report_preparse_log.append(msg)

        batch_result = process_documents_batch(
            pdf_paths=pdf_files,
            max_pages_per_pdf=max_pages,
            max_total_images=20,  # Claude ì œí•œ
            output_mode="structured",
            progress_callback=progress_cb,
        )

        progress.progress(0.7)
        st.session_state.report_preparse_progress = 0.7

        if batch_result.get("success"):
            # ë°°ì¹˜ ê²°ê³¼ë¥¼ ê°œë³„ íŒŒì¼ ê²°ê³¼ë¡œ ë¶„ë°° (í˜¸í™˜ì„± ìœ ì§€)
            for pdf_path in pdf_files:
                filename = Path(pdf_path).name
                results[pdf_path] = {
                    "pdf": {
                        "success": True,
                        "content": batch_result.get("content", ""),
                        "financial_tables": batch_result.get("financial_tables", {}),
                        "investment_terms": batch_result.get("investment_terms", {}),
                        "company_info": batch_result.get("company_info", {}),
                        "processing_method": "claude_opus_batch",
                        "pages_read": batch_result.get("file_page_map", {}).get(filename, 0),
                        "total_pages": batch_result.get("file_page_map", {}).get(filename, 0),
                        # ë°°ì¹˜ ì „ì²´ ì •ë³´
                        "_batch_source_files": batch_result.get("source_files", []),
                        "_batch_total_images": batch_result.get("total_images", 0),
                    }
                }
            st.session_state.report_preparse_log.append(
                f"PDF ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ ({batch_result.get('processing_time_seconds', 0):.1f}ì´ˆ)"
            )

            # Market evidenceëŠ” ë³„ë„ë¡œ (ì„ íƒì )
            if include_market_evidence:
                for pdf_path in pdf_files:
                    evidence_result = execute_extract_pdf_market_evidence(
                        pdf_path=pdf_path,
                        max_pages=max_pages,
                        max_results=20,
                    )
                    results[pdf_path]["market_evidence"] = evidence_result
        else:
            st.error(f"PDF ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {batch_result.get('error', 'Unknown error')}")
            for pdf_path in pdf_files:
                results[pdf_path] = {"pdf": {"success": False, "error": batch_result.get("error")}}

    # 2. Excel/DOCXëŠ” ê°œë³„ ì²˜ë¦¬
    for idx, path in enumerate(other_files):
        filename = Path(path).name
        st.session_state.report_preparse_current = filename
        ext = Path(path).suffix.lower()

        if ext in [".xlsx", ".xls"]:
            excel_result = execute_read_excel_as_text(excel_path=path, max_rows=80)
            results[path] = {"excel": excel_result}
        elif ext == ".docx":
            docx_result = execute_read_docx_as_text(docx_path=path, max_paragraphs=200)
            results[path] = {"docx": docx_result}
        else:
            results[path] = {"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹"}

        st.session_state.report_preparse_log.append(f"ì™„ë£Œ: {filename}")

    progress.progress(1.0)
    st.session_state.report_preparse_results = results
    st.session_state.report_preparse_summary = _build_preparse_summary(results)
    st.session_state.report_preparse_at = datetime.now().isoformat()
    st.session_state.report_preparse_status = "done"
    st.session_state.report_preparse_progress = 1.0
    st.session_state.report_preparse_current = ""
    status.markdown("âœ… ì¼ê´„ íŒŒì‹± ì™„ë£Œ")


def _preparse_report_files(
    max_pages: int,
    include_market_evidence: bool,
    ocr_mode: str,
    min_text_chars: int,
    max_ocr_pages: int,
) -> None:
    """ê°œë³„ íŒŒì¼ë³„ íŒŒì‹± (ê¸°ì¡´ ë°©ì‹, í˜¸í™˜ì„± ìœ ì§€)"""
    st.session_state.report_preparse_status = "running"
    st.session_state.report_preparse_progress = 0.0
    st.session_state.report_preparse_current = ""
    st.session_state.report_preparse_log = []

    files = list(st.session_state.get("unified_files", []))
    missing_files = [f for f in files if not Path(f).exists()]
    if missing_files:
        st.warning(
            "ì¼ë¶€ ì—…ë¡œë“œ íŒŒì¼ì´ ì„ì‹œ ì €ì¥ì†Œì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. "
            "ë‹¤ì‹œ ì—…ë¡œë“œí•œ í›„ íŒŒì‹±ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”."
        )
        st.session_state.report_preparse_log.append(
            f"ëˆ„ë½ íŒŒì¼ {len(missing_files)}ê°œ ê°ì§€"
        )
        files = [f for f in files if Path(f).exists()]
        st.session_state.unified_files = files
    if not files:
        st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.session_state.report_preparse_status = "idle"
        return

    st.session_state.report_preparse_total = len(files)
    results = {}
    progress = st.progress(0.0)
    status = st.empty()

    total = len(files)
    for idx, path in enumerate(files, start=1):
        filename = Path(path).name
        st.session_state.report_preparse_current = filename
        st.session_state.report_preparse_progress = min((idx - 1) / max(total, 1), 0.95)
        st.session_state.report_preparse_log.append(f"ì‹œì‘: {filename}")
        status.markdown(
            f"<div class='report-preparse-status'>ğŸ“¥ {filename} íŒŒì‹± ì¤‘...</div>",
            unsafe_allow_html=True,
        )
        ext = Path(path).suffix.lower()
        if ext == ".pdf":
            pdf_result = execute_read_pdf_as_text(
                pdf_path=path,
                max_pages=max_pages,
                output_mode="structured" if ocr_mode != "pymupdf" else "text_only",
                extract_financial_tables=ocr_mode != "pymupdf",
                ocr_mode=ocr_mode,
                min_text_chars=min_text_chars,
                max_ocr_pages=max_ocr_pages,
            )
            result_entry = {"pdf": pdf_result}
            if include_market_evidence:
                evidence_result = execute_extract_pdf_market_evidence(
                    pdf_path=path,
                    max_pages=max_pages,
                    max_results=20,
                )
                result_entry["market_evidence"] = evidence_result
            results[path] = result_entry
        elif ext in [".xlsx", ".xls"]:
            excel_result = execute_read_excel_as_text(
                excel_path=path,
                max_rows=80,
            )
            results[path] = {"excel": excel_result}
        elif ext == ".docx":
            docx_result = execute_read_docx_as_text(
                docx_path=path,
                max_paragraphs=200,
            )
            results[path] = {"docx": docx_result}
        else:
            results[path] = {"error": "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹"}

        progress.progress(idx / total)
        st.session_state.report_preparse_progress = min(idx / max(total, 1), 0.98)
        st.session_state.report_preparse_log.append(f"ì™„ë£Œ: {filename}")

    st.session_state.report_preparse_results = results
    st.session_state.report_preparse_summary = _build_preparse_summary(results)
    st.session_state.report_preparse_at = datetime.now().isoformat()
    st.session_state.report_preparse_status = "done"
    st.session_state.report_preparse_progress = 1.0
    st.session_state.report_preparse_current = ""
    status.markdown("âœ… ì¼ê´„ íŒŒì‹± ì™„ë£Œ")


def save_uploaded_file(uploaded_file) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ temp ë””ë ‰í† ë¦¬ì— ì €ì¥"""
    user_id = st.session_state.get("user_id", "anonymous")
    all_extensions = set(ALLOWED_EXTENSIONS_PDF) | set(ALLOWED_EXTENSIONS_EXCEL) | {".docx", ".doc"}

    is_valid, error = validate_upload(
        filename=uploaded_file.name,
        file_size=uploaded_file.size,
        allowed_extensions=all_extensions,
    )
    if not is_valid:
        st.error(error)
        return None

    file_path = get_secure_upload_path(user_id=user_id, original_filename=uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    # íˆ¬ìì‹¬ì‚¬ ì›Œí¬í”Œë¡œì—ì„œëŠ” ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ìœ ì§€í•´ì•¼ í•¨
    max_files = 10
    if st.session_state.get("report_panel_enabled"):
        max_files = max(50, len(st.session_state.get("unified_files", [])) + 10)
    cleanup_user_temp_files(user_id, max_files=max_files)
    return str(file_path)


def compact_conversation(messages: list, api_key: str) -> tuple[list, bool]:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ìš”ì•½í•˜ì—¬ ì»´íŒ©íŠ¸

    Args:
        messages: í˜„ì¬ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        api_key: Claude API í‚¤

    Returns:
        (ì»´íŒ©íŠ¸ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸, ì»´íŒ©ì…˜ ì„±ê³µ ì—¬ë¶€)
    """
    COMPACTION_TRIGGER = 15
    COMPACTION_TARGET = 10

    if len(messages) < COMPACTION_TRIGGER:
        return messages, False

    # ìš”ì•½í•  ë©”ì‹œì§€ (ì²« 10ê°œ)
    to_compact = messages[:COMPACTION_TARGET]
    remaining = messages[COMPACTION_TARGET:]

    # ìš”ì•½ ìƒì„±
    try:
        from anthropic import Anthropic
        client = Anthropic(api_key=api_key)

        # ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (system ë©”ì‹œì§€ëŠ” ì œì™¸)
        conversation_text = "\n\n".join([
            f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['content'][:500]}"  # ê¸´ ì‘ë‹µ ì˜ë¼ë‚´ê¸°
            for msg in to_compact
            if msg['role'] != 'system'
        ])

        # Claudeì—ê²Œ ìš”ì•½ ìš”ì²­
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",  # ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸
            max_tokens=500,
            messages=[{
                "role": "user",
                "content": f"""ë‹¤ìŒì€ VC íˆ¬ì ë¶„ì„ ëŒ€í™”ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.
ì´ ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ì •ë³´ë§Œ í¬í•¨í•˜ê³ , 3-5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

{conversation_text}

ìš”ì•½:"""
            }]
        )

        summary = response.content[0].text.strip()

        # ìš”ì•½ì„ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì¶”ê°€
        compacted = [{
            "role": "system",
            "content": f"[ì´ì „ ëŒ€í™” ìš”ì•½]\n{summary}"
        }]

        # ë‚˜ë¨¸ì§€ ë©”ì‹œì§€ ì¶”ê°€
        compacted.extend(remaining)

        return compacted, True

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.warning(f"ëŒ€í™” ì»´íŒ©ì…˜ ì‹¤íŒ¨: {e}")
        # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ (ë‹¨ìˆœ ì‚­ì œ)
        return messages[-COMPACTION_TRIGGER:], False


use_report_panel = st.session_state.get("report_panel_enabled", False)
if use_report_panel:
    st.session_state.unified_mode = "report"
    chat_col, report_col = st.columns([1.15, 0.85], gap="large")
else:
    chat_col = st.container()
    report_col = None

report_stream_placeholder = None
report_status_placeholder = None
report_log_placeholder = None
chapter_order = []
current_chapter = None

if use_report_panel and report_col is not None:
    with report_col:
        st.markdown("## íˆ¬ìì‹¬ì‚¬ ë³´ê³ ì„œ")
        with st.expander("ìë£Œ ì¤€ë¹„/ì¼ê´„ íŒŒì‹±", expanded=True):
            uploader_key = f"report_panel_uploader_{st.session_state.report_panel_uploader_seed}"
            uploaded_panel_files = st.file_uploader(
                "ì—¬ê¸°ì— íŒŒì¼ì„ ë“œë˜ê·¸ì•¤ë“œë¡­í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš” (PDF, ì—‘ì…€, DOCX)",
                type=["pdf", "xlsx", "xls", "docx", "doc"],
                accept_multiple_files=True,
                key=uploader_key,
                help="íˆ¬ìì‹¬ì‚¬ ë³´ê³ ì„œì— ì‚¬ìš©í•  ìë£Œë¥¼ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ì„¸ìš”."
            )

            if uploaded_panel_files:
                processed_keys = set(st.session_state.get("processed_upload_keys", []))
                new_upload_processed = False
                for uploaded_file in uploaded_panel_files:
                    upload_key = f"{uploaded_file.name}|{uploaded_file.size}"
                    if upload_key in processed_keys:
                        continue
                    processed_keys.add(upload_key)
                    file_path = save_uploaded_file(uploaded_file)
                    if file_path and file_path not in st.session_state.unified_files:
                        st.session_state.unified_files.append(file_path)
                        new_upload_processed = True
                st.session_state.processed_upload_keys = sorted(processed_keys)
                if new_upload_processed:
                    st.session_state.report_panel_uploader_seed += 1
                    st.rerun()

            files = st.session_state.get("unified_files", [])
            if st.session_state.get("report_preparse_status") == "running":
                total = st.session_state.get("report_preparse_total", 0)
                current = st.session_state.get("report_preparse_current") or "ì§„í–‰ ì¤‘..."
                st.info(f"íŒŒì‹± ì¤‘: {current} ({len(st.session_state.get('report_preparse_log', []))//2}/{total})")
                st.progress(st.session_state.get("report_preparse_progress", 0.0))
                with st.expander("íŒŒì‹± ë¡œê·¸", expanded=False):
                    logs = st.session_state.get("report_preparse_log", [])
                    if logs:
                        st.markdown("\n".join([f"- {line}" for line in logs[-10:]]))
                    else:
                        st.caption("ë¡œê·¸ ì—†ìŒ")
            if files:
                st.caption(f"ì—…ë¡œë“œ íŒŒì¼ {len(files)}ê°œ")
                for fpath in files:
                    st.markdown(f"- {Path(fpath).name}")

                options_cols = st.columns([1, 1])
                with options_cols[0]:
                    st.session_state.report_preparse_max_pages = st.slider(
                        "PDF ìµœëŒ€ í˜ì´ì§€",
                        min_value=5,
                        max_value=80,
                        value=st.session_state.report_preparse_max_pages,
                        step=5,
                        help="í˜ì´ì§€ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.",
                    )
                with options_cols[1]:
                    st.session_state.report_preparse_market_evidence = st.checkbox(
                        "ì‹œì¥ê·¼ê±° ì¶”ì¶œ í¬í•¨ (ëŠë¦¼)",
                        value=st.session_state.report_preparse_market_evidence,
                        help="PDF ë‚´ ì‹œì¥ê·œëª¨ ê·¼ê±° ë¬¸ì¥ì„ ë³„ë„ ì¶”ì¶œí•©ë‹ˆë‹¤.",
                    )
                mode_options = [
                    "ğŸš€ ë°°ì¹˜ ëª¨ë“œ (ì¶”ì²œ)",
                    "ì •í™•ë„ ìš°ì„  (Vision)",
                    "ì¤‘ê°„ ì •í™•ë„ (Hybrid)",
                    "ë¹ ë¥¸ íŒŒì‹± (í…ìŠ¤íŠ¸ë§Œ)",
                ]
                current_mode = st.session_state.report_preparse_mode
                if current_mode not in mode_options:
                    current_mode = mode_options[0]
                st.session_state.report_preparse_mode = st.selectbox(
                    "íŒŒì‹± ëª¨ë“œ",
                    options=mode_options,
                    index=mode_options.index(current_mode),
                    help="ë°°ì¹˜ ëª¨ë“œ: ëª¨ë“  PDFë¥¼ í•©ì³ì„œ í•œ ë²ˆì— ë¶„ì„ (ë¹ ë¥´ê³  íš¨ìœ¨ì ). Vision: ê°œë³„ ì²˜ë¦¬.",
                )

                if st.session_state.report_preparse_mode == "ì¤‘ê°„ ì •í™•ë„ (Hybrid)":
                    hybrid_cols = st.columns([1, 1])
                    with hybrid_cols[0]:
                        st.session_state.report_preparse_min_text_chars = st.slider(
                            "ì €í…ìŠ¤íŠ¸ ê¸°ì¤€(ë¬¸ì ìˆ˜)",
                            min_value=50,
                            max_value=400,
                            value=st.session_state.report_preparse_min_text_chars,
                            step=25,
                            help="ì´ ê¸°ì¤€ë³´ë‹¤ í…ìŠ¤íŠ¸ê°€ ì ì€ í˜ì´ì§€ëŠ” OCR ë³´ê°• ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.",
                        )
                    with hybrid_cols[1]:
                        st.session_state.report_preparse_max_ocr_pages = st.slider(
                            "OCR ë³´ê°• í˜ì´ì§€ ìˆ˜",
                            min_value=1,
                            max_value=15,
                            value=st.session_state.report_preparse_max_ocr_pages,
                            step=1,
                            help="ë³´ê°•í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.",
                        )

                cols = st.columns([1, 1])
                with cols[0]:
                    if st.button("ì™„ë£Œ (ì¼ê´„ íŒŒì‹±)", use_container_width=True):
                        mode = st.session_state.report_preparse_mode

                        if mode == "ğŸš€ ë°°ì¹˜ ëª¨ë“œ (ì¶”ì²œ)":
                            # ë°°ì¹˜ ëª¨ë“œ: ëª¨ë“  PDFë¥¼ í•©ì³ì„œ í•œ ë²ˆì— ì²˜ë¦¬
                            _preparse_report_files_batch(
                                max_pages=st.session_state.report_preparse_max_pages,
                                include_market_evidence=st.session_state.report_preparse_market_evidence,
                            )
                        else:
                            # ê¸°ì¡´ ê°œë³„ ì²˜ë¦¬ ëª¨ë“œ
                            ocr_mode = "vision"
                            if mode == "ì¤‘ê°„ ì •í™•ë„ (Hybrid)":
                                ocr_mode = "hybrid"
                            elif mode == "ë¹ ë¥¸ íŒŒì‹± (í…ìŠ¤íŠ¸ë§Œ)":
                                ocr_mode = "pymupdf"

                            _preparse_report_files(
                                max_pages=st.session_state.report_preparse_max_pages,
                                include_market_evidence=st.session_state.report_preparse_market_evidence,
                                ocr_mode=ocr_mode,
                                min_text_chars=st.session_state.report_preparse_min_text_chars,
                                max_ocr_pages=st.session_state.report_preparse_max_ocr_pages,
                            )
                        st.session_state.report_panel_uploader_seed += 1
                        st.rerun()
                with cols[1]:
                    if st.button("íŒŒì‹± ìš”ì•½ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
                        st.session_state.report_preparse_summary = _build_preparse_summary(
                            st.session_state.get("report_preparse_results", {})
                        )
                        st.rerun()
            else:
                st.info("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ë“œë˜ê·¸ì•¤ë“œë¡­í•˜ê±°ë‚˜ MDë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

            if st.session_state.get("report_preparse_at"):
                st.caption(f"ë§ˆì§€ë§‰ íŒŒì‹±: {st.session_state.report_preparse_at}")
            if st.session_state.get("report_md_imported_at"):
                st.caption(f"MD ë³µêµ¬ ì‹œê°: {st.session_state.report_md_imported_at}")

            summary = st.session_state.get("report_preparse_summary", [])
            if summary:
                st.table(summary)

            md_upload = st.file_uploader(
                "MD ì—…ë¡œë“œ (ë³µêµ¬)",
                type=["md", "markdown", "txt"],
                accept_multiple_files=False,
                key="report_md_uploader",
                help="MerryParse/Evidence Pack MDë¥¼ ì—…ë¡œë“œí•˜ë©´ íŒŒì‹± ìš”ì•½/ì»¨í…ìŠ¤íŠ¸ë¥¼ ë³µêµ¬í•©ë‹ˆë‹¤.",
            )
            if md_upload is not None:
                try:
                    md_text = md_upload.getvalue().decode("utf-8", errors="ignore")
                    _restore_from_md(md_text)
                    st.success("MD ë³µêµ¬ ì™„ë£Œ. íŒŒì‹± ìš”ì•½ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
                    st.rerun()
                except Exception as exc:
                    st.error(f"MD ë³µêµ¬ ì‹¤íŒ¨: {exc}")

            evidence_pack_md = st.session_state.get("report_evidence_pack_md")
            if summary or evidence_pack_md:
                md_content, md_label = _build_preparse_md()
                if evidence_pack_md:
                    md_content = evidence_pack_md
                    md_label = st.session_state.get("report_evidence_pack_company") or _derive_company_label(files)
                quality = _extract_evidence_pack_quality(md_content)
                stale = _is_evidence_pack_stale()
                if evidence_pack_md and quality.get("evidence_count", 0) == 0:
                    st.warning(
                        "Evidence Packì— ê·¼ê±° ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. "
                        "íŒŒì‹± ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  í•„ìš” ì‹œ ë³´ì™„í•´ ì£¼ì„¸ìš”."
                    )
                if stale:
                    st.warning("Evidence Packì´ ìµœì‹  íŒŒì‹±ê³¼ ì—°ê²°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬ìƒì„± ê¶Œì¥ (í˜„ì¬ MD ìš°ì„  ì‚¬ìš©).")
                st.download_button(
                    label="Evidence Pack MD ë‹¤ìš´ë¡œë“œ",
                    data=md_content,
                    file_name=f"evidence_pack_{md_label}_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                    mime="text/markdown",
                    use_container_width=True,
                    disabled=not evidence_pack_md,
                )

            with st.expander("Evidence Pack ìƒì„± (Opus)", expanded=False):
                if st.session_state.report_evidence_pack_raw_status == "running":
                    st.info("Evidence Pack ë¹ ë¥¸ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤...")
                if st.session_state.report_evidence_pack_status == "running":
                    st.info("Evidence Pack ì •ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
                st.session_state.report_evidence_pack_company = st.text_input(
                    "ê¸°ì—…ëª…",
                    value=st.session_state.report_evidence_pack_company,
                    placeholder="ì˜ˆ: ì£¼ì‹íšŒì‚¬ ìŠ¤íŠ¸ë ˆìŠ¤ì†”ë£¨ì…˜",
                )
                extract_col, format_col = st.columns([1, 1])
                with extract_col:
                    if st.button(
                        "ë¹ ë¥¸ ì¶”ì¶œ (Raw)",
                        use_container_width=True,
                        disabled=not files or not st.session_state.report_evidence_pack_company.strip(),
                    ):
                        api_key = st.session_state.get("user_api_key") or st.secrets.get("anthropic_api_key", "")
                        if not api_key:
                            st.error("Claude API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            st.session_state.report_evidence_pack_raw_status = "running"
                            stage1_md = st.session_state.get("report_preparse_stage1_md") or _build_stage1_markdown(
                                st.session_state.get("report_preparse_results", {})
                            )
                            condensed = _condense_stage1_for_extract(stage1_md)
                            evidence_items = _collect_market_evidence(
                                st.session_state.get("report_preparse_results", {})
                            )
                            summary_block = _build_preparse_summary_block(
                                st.session_state.get("report_preparse_summary", [])
                            )
                            structured_financial = _collect_structured_financial_data(
                                st.session_state.get("report_preparse_results", {})
                            )
                            prompt = _build_evidence_pack_extract_prompt(condensed, evidence_items, summary_block, structured_financial)
                            try:
                                from anthropic import Anthropic
                                client = Anthropic(api_key=api_key)
                                response = client.messages.create(
                                    model="claude-opus-4-5-20251101",
                                    max_tokens=3500,
                                    temperature=0.2,
                                    messages=[{"role": "user", "content": prompt}],
                                )
                                text = response.content[0].text if response.content else ""
                                st.session_state.report_evidence_pack_raw = text.strip()
                                st.session_state.report_evidence_pack_raw_at = datetime.now().isoformat()
                                st.session_state.report_evidence_pack_raw_status = "done"
                                st.success("ë¹ ë¥¸ ì¶”ì¶œ ì™„ë£Œ")
                                st.rerun()
                            except Exception as exc:
                                st.session_state.report_evidence_pack_raw_status = "idle"
                                st.error(f"ë¹ ë¥¸ ì¶”ì¶œ ì‹¤íŒ¨: {exc}")
                with format_col:
                    if st.button(
                        "ì •ë¦¬í•´ì„œ Evidence Pack ìƒì„±",
                        use_container_width=True,
                        disabled=not st.session_state.report_evidence_pack_raw or not st.session_state.report_evidence_pack_company.strip(),
                    ):
                        api_key = st.session_state.get("user_api_key") or st.secrets.get("anthropic_api_key", "")
                        if not api_key:
                            st.error("Claude API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            st.session_state.report_evidence_pack_status = "running"
                            summary_block = _build_preparse_summary_block(
                                st.session_state.get("report_preparse_summary", [])
                            )
                            prompt = _build_evidence_pack_format_prompt(
                                st.session_state.report_evidence_pack_raw, summary_block
                            )
                            try:
                                from anthropic import Anthropic
                                client = Anthropic(api_key=api_key)
                                response = client.messages.create(
                                    model="claude-opus-4-5-20251101",
                                    max_tokens=6000,
                                    temperature=0.2,
                                    messages=[{"role": "user", "content": prompt}],
                                )
                                text = response.content[0].text if response.content else ""
                                st.session_state.report_evidence_pack_md = text.strip()
                                st.session_state.report_evidence_pack_at = datetime.now().isoformat()
                                st.session_state.report_evidence_pack_status = "done"
                                quality = _extract_evidence_pack_quality(st.session_state.report_evidence_pack_md)
                                if quality.get("evidence_count", 0) == 0:
                                    st.warning(
                                        "Evidence Pack ìƒì„± ì™„ë£Œí–ˆì§€ë§Œ ê·¼ê±° ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. "
                                        "íŒŒì‹± ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ìë£Œë¥¼ ë³´ì™„í•´ ì£¼ì„¸ìš”."
                                    )
                                else:
                                    st.success("Evidence Pack ìƒì„± ì™„ë£Œ")
                                st.rerun()
                            except Exception as exc:
                                st.session_state.report_evidence_pack_status = "idle"
                                st.error(f"Evidence Pack ìƒì„± ì‹¤íŒ¨: {exc}")

                if st.session_state.get("report_evidence_pack_raw"):
                    with st.expander("ë¹ ë¥¸ ì¶”ì¶œ ê²°ê³¼(JSON)", expanded=False):
                        st.code(st.session_state.report_evidence_pack_raw, language="json")

        chapter_order = _init_report_chapters()
        if chapter_order:
            st.session_state.report_chapter_index = max(
                0,
                min(st.session_state.get("report_chapter_index", 0), len(chapter_order) - 1),
            )
            current_chapter = chapter_order[st.session_state.report_chapter_index]
            status = st.session_state.get("report_chapter_status", {}).get(current_chapter, "draft")
            st.caption(f"í˜„ì¬ ì±•í„°: {current_chapter} Â· ìƒíƒœ: {status} Â· "
                       f"{st.session_state.report_chapter_index + 1}/{len(chapter_order)}")
            st.progress((st.session_state.report_chapter_index + 1) / len(chapter_order))
        else:
            st.caption("ëª©ì°¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        report_status_placeholder = st.empty()
        report_log_placeholder = st.empty()
        report_status_placeholder.markdown("â³ ìƒíƒœ: ëŒ€ê¸° ì¤‘")
        report_log_placeholder.markdown("ë„êµ¬ ë¡œê·¸: ì—†ìŒ")

        report_stream_placeholder = st.empty()
        existing = st.session_state.get("report_chapters", {}).get(current_chapter, "") if current_chapter else ""
        if existing and not st.session_state.get("report_edit_buffer"):
            st.session_state.report_edit_buffer = existing
        if not existing:
            report_stream_placeholder.markdown("ì´ˆì•ˆì´ ìƒì„±ë˜ë©´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

        st.text_area(
            "í¸ì§‘",
            key="report_edit_buffer",
            height=280,
            placeholder="ì±•í„° ë‚´ìš©ì„ í¸ì§‘í•˜ì„¸ìš”.",
        )

        if chapter_order:
            btn_cols = st.columns(3)
            idx = st.session_state.get("report_chapter_index", 0)
            idx = max(0, min(idx, len(chapter_order) - 1))
            with btn_cols[0]:
                if st.button("ì´ì „", use_container_width=True, disabled=idx == 0):
                    _save_current_chapter(mark_done=False)
                    st.session_state.report_chapter_index = max(0, idx - 1)
                    st.session_state.report_edit_buffer = st.session_state.report_chapters.get(
                        chapter_order[st.session_state.report_chapter_index], ""
                    )
                    st.rerun()
            with btn_cols[1]:
                if st.button("ì™„ë£Œ", use_container_width=True):
                    _save_current_chapter(mark_done=True)
                    if idx < len(chapter_order) - 1:
                        st.session_state.report_chapter_index = idx + 1
                        st.session_state.report_edit_buffer = st.session_state.report_chapters.get(
                            chapter_order[idx + 1], ""
                        )
                    st.rerun()
            with btn_cols[2]:
                if st.button("ë‹¤ìŒ", use_container_width=True, disabled=idx >= len(chapter_order) - 1):
                    _save_current_chapter(mark_done=False)
                    st.session_state.report_chapter_index = min(len(chapter_order) - 1, idx + 1)
                    st.session_state.report_edit_buffer = st.session_state.report_chapters.get(
                        chapter_order[st.session_state.report_chapter_index], ""
                    )
                    st.rerun()

with chat_col:
    # ========================================
    # Welcome í™”ë©´ (ë©”ì‹œì§€ê°€ ì—†ì„ ë•Œë§Œ í‘œì‹œ)
    # ========================================
    if not st.session_state.unified_messages:
        st.markdown("""
        <div class="welcome-screen">
            <div class="welcome-screen__title">ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?</div>
            <div class="welcome-screen__subtitle">
                íˆ¬ì ë¶„ì„, ê¸°ì—… ì§„ë‹¨, ê³„ì•½ì„œ ê²€í†  ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ ì´ìš©í•˜ì„¸ìš”
            </div>
        </div>
        """, unsafe_allow_html=True)

        # ê¸°ëŠ¥ Pills
        st.markdown("### ì£¼ìš” ê¸°ëŠ¥")

        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("Exit í”„ë¡œì ì…˜", key="pill_exit", use_container_width=True):
                st.session_state.quick_cmd = "íˆ¬ìê²€í†  ì—‘ì…€ íŒŒì¼ì„ ë¶„ì„í•´ì„œ Exit í”„ë¡œì ì…˜ì„ ë§Œë“¤ì–´ì¤˜"
                st.rerun()

        with col2:
            if st.button("Peer PER ë¶„ì„", key="pill_peer", use_container_width=True):
                st.session_state.quick_cmd = "ìœ ì‚¬ê¸°ì—… PERì„ ë¹„êµ ë¶„ì„í•´ì¤˜"
                st.rerun()

        with col3:
            if st.button("ê¸°ì—… ì§„ë‹¨", key="pill_diagnosis", use_container_width=True):
                st.session_state.quick_cmd = "ì§„ë‹¨ì‹œíŠ¸ë¥¼ ë¶„ì„í•˜ê³  ì»¨ì„¤í„´íŠ¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜"
                st.rerun()

        col4, col5, col6 = st.columns(3)
        with col4:
            if st.button("íˆ¬ìë³´ê³ ì„œ", key="pill_report", use_container_width=True):
                st.session_state.report_panel_enabled = True
                st.session_state.unified_mode = "report"
                st.toast("íˆ¬ìë³´ê³ ì„œ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

        with col5:
            if st.button("ìŠ¤íƒ€íŠ¸ì—… ë°œêµ´", key="pill_discovery", use_container_width=True):
                st.session_state.quick_cmd = "ì •ì±… PDFë¥¼ ë¶„ì„í•´ì„œ ìœ ë§ ì‚°ì—…ì„ ì¶”ì²œí•´ì¤˜"
                st.rerun()

        with col6:
            if st.button("ê³„ì•½ì„œ ê²€í† ", key="pill_contract", use_container_width=True):
                st.session_state.quick_cmd = "ê³„ì•½ì„œë¥¼ ë¶„ì„í•˜ê³  ì£¼ìš” ì¡°í•­ì„ ê²€í† í•´ì¤˜"
                st.rerun()

        col7, col8 = st.columns(2)
        with col7:
            if st.button("íŒ€ í˜‘ì—…", key="pill_collab", use_container_width=True):
                st.session_state.quick_cmd = "íŒ€ ê³¼ì—… í˜„í™©ì„ ë³´ì—¬ì¤˜"
                st.rerun()

        with col8:
            if st.button("ê³µê³µì…ì°° ê²€ìƒ‰", key="pill_bid", use_container_width=True):
                st.session_state.quick_cmd = "ë‚˜ë¼ì¥í„°ì—ì„œ ê´€ë ¨ ì…ì°° ê³µê³ ë¥¼ ì°¾ì•„ì¤˜"
                st.rerun()

    # ========================================
    # ëŒ€í™” ì˜ì—­
    # ========================================
    chat_container = st.container()

    with chat_container:
        for msg in st.session_state.unified_messages:
            role = msg.get("role", "")
            content = msg.get("content", "")
            tool_logs = msg.get("tool_logs", [])

            if role == "user":
                with st.chat_message("user", avatar=user_avatar_image):
                    st.markdown(content)

            elif role == "system":
                # ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ëŒ€í™” ìš”ì•½)
                st.markdown(f"""
                <div class="system-message">
                    <strong>ğŸ“ {content.split(']')[0]}]</strong>
                    <div style="margin-top: 0.5rem; color: var(--text-secondary);">
                        {content.split(']', 1)[1] if ']' in content else content}
                    </div>
                </div>
                """, unsafe_allow_html=True)

            elif role == "assistant":
                with st.chat_message("assistant", avatar=avatar_image):
                    # Tool logs í‘œì‹œ
                    if tool_logs:
                        for log in tool_logs:
                            if log.startswith("**ë„êµ¬:"):
                                # Tool execution ì¹´ë“œ
                                tool_name = log.replace("**ë„êµ¬:", "").replace("**", "").strip()
                                st.markdown(f"""
                                <div class="tool-card tool-card--running">
                                    <div class="tool-card__header">
                                        {tool_name}
                                        <div class="tool-spinner"></div>
                                    </div>
                                    <div class="tool-card__body">
                                        ì‹¤í–‰ ì¤‘...
                                    </div>
                                </div>
                                """, unsafe_allow_html=True)

                    st.markdown(content)

                    # Tool logs expander
                    if tool_logs:
                        with st.expander("ì‹¤í–‰ ë¡œê·¸", expanded=False):
                            for line in tool_logs:
                                st.caption(line)

    # Auto-scroll to bottom
    if st.session_state.unified_messages:
        st.markdown("""
        <script>
        window.scrollTo(0, document.body.scrollHeight);
        </script>
        """, unsafe_allow_html=True)

# ========================================
# í•˜ë‹¨ ê³ ì • ì˜ì—­: íŒŒì¼ ì²¨ë¶€ + ì±„íŒ… ì…ë ¥
# ========================================

    # ì²¨ë¶€ëœ íŒŒì¼ í‘œì‹œ (í•˜ë‹¨ ê³ ì •)
    if st.session_state.unified_files:
        st.markdown('<div class="fixed-file-area">', unsafe_allow_html=True)
        for i, fpath in enumerate(st.session_state.unified_files):
            fname = Path(fpath).name
            col1, col2 = st.columns([5, 1])
            with col1:
                st.markdown(f"""
                <div class="file-chip">
                    {fname}
                </div>
                """, unsafe_allow_html=True)
            with col2:
                if st.button("Ã—", key=f"remove_{i}", help="ì œê±°"):
                    removed_path = st.session_state.unified_files.pop(i)
                    try:
                        removed_name = Path(removed_path).name
                        removed_size = Path(removed_path).stat().st_size
                        removed_key = f"{removed_name}|{removed_size}"
                        processed_keys = set(st.session_state.get("processed_upload_keys", []))
                        if removed_key in processed_keys:
                            processed_keys.remove(removed_key)
                            st.session_state.processed_upload_keys = sorted(processed_keys)
                    except FileNotFoundError:
                        pass
                    st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)

    # íŒŒì¼ ì²¨ë¶€ ë²„íŠ¼
    with st.expander("íŒŒì¼ ì²¨ë¶€", expanded=False):
        uploader_key = f"unified_file_uploader_{st.session_state.uploader_key_seed}"
        uploaded_files = st.file_uploader(
            "ë¶„ì„í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (PDF, ì—‘ì…€, DOCX)",
            type=["pdf", "xlsx", "xls", "docx", "doc"],
            accept_multiple_files=True,
            key=uploader_key,
            help="íˆ¬ìê²€í†  ì—‘ì…€, ê¸°ì—…ì†Œê°œì„œ PDF, ì§„ë‹¨ì‹œíŠ¸, ê³„ì•½ì„œ ë“± ëª¨ë“  íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
        )

        if uploaded_files:
            processed_keys = set(st.session_state.get("processed_upload_keys", []))
            new_upload_processed = False
            for uploaded_file in uploaded_files:
                upload_key = f"{uploaded_file.name}|{uploaded_file.size}"
                if upload_key in processed_keys:
                    continue
                processed_keys.add(upload_key)
                # PDF íŒŒì¼ì¸ ê²½ìš° ë¡œë”©ë°” í‘œì‹œ
                if uploaded_file.name.lower().endswith('.pdf'):
                    import time

                    # ë¡œë”©ë°” í‘œì‹œ
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    status_text.text(f"ğŸ“„ {uploaded_file.name} ì—…ë¡œë“œ ì¤‘...")

                    # 30ì´ˆ ë™ì•ˆ ì§„í–‰
                    for percent in range(101):
                        time.sleep(0.3)  # 30ì´ˆ = 100 * 0.3
                        progress_bar.progress(percent)
                        if percent < 100:
                            status_text.text(f"ğŸ“„ {uploaded_file.name} ì—…ë¡œë“œ ì¤‘... {percent}%")

                    # íŒŒì¼ ì €ì¥
                    file_path = save_uploaded_file(uploaded_file)

                    if file_path and file_path not in st.session_state.unified_files:
                        st.session_state.unified_files.append(file_path)
                        new_upload_processed = True
                        progress_bar.empty()
                        status_text.empty()

                        # ì™„ë£Œ í† ìŠ¤íŠ¸
                        st.toast(f"âœ… {uploaded_file.name} ì—…ë¡œë“œ ì™„ë£Œ", icon="âœ…")

                        # ì£¼ì˜ ë¬¸êµ¬ í‘œì‹œ
                        st.warning(f"âš ï¸ **{uploaded_file.name}** ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ íŒŒì¼ ë¶„ì„ì„ ìš”ì²­í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", icon="âš ï¸")
                        time.sleep(2)  # 2ì´ˆê°„ í‘œì‹œ
                else:
                    # PDFê°€ ì•„ë‹Œ íŒŒì¼ì€ ì¦‰ì‹œ ì—…ë¡œë“œ
                    file_path = save_uploaded_file(uploaded_file)
                    if file_path and file_path not in st.session_state.unified_files:
                        st.session_state.unified_files.append(file_path)
                        st.toast(f"{uploaded_file.name} ì—…ë¡œë“œ ì™„ë£Œ")
                        new_upload_processed = True

            st.session_state.processed_upload_keys = sorted(processed_keys)
            if new_upload_processed:
                st.session_state.uploader_key_seed += 1
                st.rerun()

    # ì±„íŒ… ì…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="unified_chat_input")

with chat_col:
    # ë¹ ë¥¸ ëª…ë ¹ì–´ ì²˜ë¦¬
    if "quick_cmd" in st.session_state:
        user_input = st.session_state.quick_cmd
        del st.session_state.quick_cmd

    # ë©”ì‹œì§€ ì²˜ë¦¬
    if user_input:
        # íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        context_info = ""
        if st.session_state.unified_files:
            paths_str = ", ".join(st.session_state.unified_files)
            if "íŒŒì¼" not in user_input and "ë¶„ì„" not in user_input:
                context_info = f"\n[ì—…ë¡œë“œëœ íŒŒì¼: {paths_str}]"

        full_message = user_input + context_info
        st.session_state.unified_messages.append({"role": "user", "content": user_input})

        if st.session_state.get("report_panel_enabled"):
            has_files = bool(st.session_state.unified_files)
            has_md = bool(st.session_state.get("report_evidence_pack_md"))
            if not has_files and not has_md:
                guidance = (
                    "íˆ¬ìì‹¬ì‚¬ ë³´ê³ ì„œë¥¼ ì´ì–´ì„œ ì‘ì„±í•˜ë ¤ë©´ ìë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                    "- ë°©ë²• 1: ì˜¤ë¥¸ìª½ íŒ¨ë„ì—ì„œ íŒŒì¼ì„ ë“œë˜ê·¸ì•¤ë“œë¡­ í›„ â€˜ì™„ë£Œ(ì¼ê´„ íŒŒì‹±)â€™\n"
                    "- ë°©ë²• 2: Evidence Pack MDë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë°”ë¡œ ì´ì–´ì“°ê¸°\n"
                    "í•„ìš”í•œ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì¦‰ì‹œ ê³„ì† ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                st.session_state.unified_messages.append({
                    "role": "assistant",
                    "content": guidance,
                    "tool_logs": [],
                })
                if report_stream_placeholder is not None:
                    report_stream_placeholder.markdown(guidance)
                if report_status_placeholder is not None:
                    report_status_placeholder.markdown("â„¹ï¸ ìƒíƒœ: ìë£Œ í•„ìš”")
                st.rerun()

        report_context_text = None
        if st.session_state.get("report_panel_enabled") and chapter_order:
            idx = st.session_state.get("report_chapter_index", 0)
            idx = max(0, min(idx, len(chapter_order) - 1))
            current_chapter = chapter_order[idx]
            file_context = ""
            if st.session_state.unified_files:
                file_context = f"ì—…ë¡œë“œ íŒŒì¼: {', '.join(st.session_state.unified_files)}"
            preparse_context = _build_preparse_context(
                st.session_state.get("report_preparse_summary", [])
            )
            report_context_text = "\n".join(filter(None, [
                file_context,
                preparse_context,
                (
                    "[Evidence Pack MD]\n"
                    + st.session_state.report_evidence_pack_md
                )
                if st.session_state.get("report_evidence_pack_md") else None,
                f"í˜„ì¬ ì‘ì„± ì±•í„°: {current_chapter}.\n"
                "ì´ ì±•í„°ë§Œ ì‘ì„±í•˜ê³  ë‹¤ë¥¸ ì±•í„°ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.\n"
                "í˜•ì‹: ### ì±•í„° ì œëª© â†’ ìš”ì•½/ê·¼ê±°/ì‹¬ì‚¬ íŒë‹¨ í¬í•¨.\n"
                "ë§ˆì§€ë§‰ì— ### ê²€ì¦ ë¡œê·¸(í•´ë‹¹ ì±•í„°) í¬í•¨.",
            ]))

        with chat_container:
            with st.chat_message("assistant", avatar=avatar_image):
                response_placeholder = st.empty()

                agent = st.session_state.agent

                try:
                    if len(st.session_state.unified_messages) >= 15:
                        with st.status("ğŸ“ ëŒ€í™” ë‚´ìš© ìš”ì•½ ì¤‘...", expanded=True) as status:
                            status.write("ğŸ’¬ 15ê°œ ì´ìƒì˜ ë©”ì‹œì§€ë¥¼ ì••ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
                            status.write("â³ Claude Haiku APIë¡œ ì´ì „ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
                            status.write("ğŸ”’ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. (ì¤‘ë³µ ìš”ì²­ ë°©ì§€)")

                            api_key = st.session_state.get("user_api_key", "")
                            compacted_messages, success = compact_conversation(
                                st.session_state.unified_messages,
                                api_key
                            )
                            st.session_state.unified_messages = compacted_messages

                            if success:
                                status.update(label="âœ… ëŒ€í™” ìš”ì•½ ì™„ë£Œ!", state="complete", expanded=False)
                                st.toast("ëŒ€í™”ê°€ ê¸¸ì–´ì ¸ ì´ì „ ë‚´ìš©ì„ ìš”ì•½í–ˆìŠµë‹ˆë‹¤", icon="ğŸ“")
                            else:
                                status.update(label="âš ï¸ ìš”ì•½ ì‹¤íŒ¨ (ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©)", state="error", expanded=False)

                    if st.session_state.get("report_panel_enabled"):
                        tool_logs = []

                        async def stream_response():
                            full_response = ""
                            log_lines = []
                            if report_status_placeholder is not None:
                                report_status_placeholder.markdown("ğŸŸ¡ ìƒíƒœ: ì‘ì„± ì¤‘...")
                            async for chunk in agent.chat(
                                full_message,
                                mode=st.session_state.get("unified_mode", "report"),
                                context_text=report_context_text,
                                model_override="claude-opus-4-5-20251101",
                            ):
                                if "**ë„êµ¬:" in chunk:
                                    tool_logs.append(chunk.strip())
                                    log_lines.append(chunk.strip())
                                    if report_log_placeholder is not None:
                                        report_log_placeholder.markdown(
                                            "ë„êµ¬ ë¡œê·¸:\n" + "\n".join([f"- {line}" for line in log_lines])
                                        )
                                else:
                                    full_response += chunk
                                    response_placeholder.markdown(full_response + "â–Œ")
                                    if report_stream_placeholder is not None:
                                        report_stream_placeholder.markdown(full_response + "â–Œ")
                            response_placeholder.markdown(full_response)
                            if report_stream_placeholder is not None:
                                report_stream_placeholder.markdown(full_response)
                            if not full_response.strip():
                                fallback_lines = [
                                    "ì´ˆì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                                    "ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ë¹„ì–´ ìˆê±°ë‚˜ íŒŒì‹±ì´ ì‹¤íŒ¨í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.",
                                    "ì¡°ì¹˜: íŒŒì‹± ëª¨ë“œë¥¼ Hybrid/ë¹ ë¥¸ íŒŒì‹±ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜, ì‹œì¥ê·¼ê±° ì¶”ì¶œì„ ëˆ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.",
                                ]
                                if tool_logs:
                                    fallback_lines.append("")
                                    fallback_lines.append("ë„êµ¬ ë¡œê·¸(ìš”ì•½):")
                                    for line in tool_logs[-6:]:
                                        cleaned = line.replace("**", "").strip()
                                        fallback_lines.append(f"- {cleaned}")
                                full_response = "\n".join(fallback_lines)
                                response_placeholder.markdown(full_response)
                                if report_stream_placeholder is not None:
                                    report_stream_placeholder.markdown(full_response)
                                if report_status_placeholder is not None:
                                    report_status_placeholder.markdown("âš ï¸ ìƒíƒœ: ì‘ì„± ì‹¤íŒ¨")
                            else:
                                if report_status_placeholder is not None:
                                    report_status_placeholder.markdown("âœ… ìƒíƒœ: ì‘ì„± ì™„ë£Œ")
                            return full_response

                        full_response = asyncio.run(stream_response())
                    else:
                        with st.spinner("ğŸ¤– ìƒê° ì¤‘..."):
                            full_response = agent.chat_sync(
                                full_message,
                                mode=st.session_state.get("unified_mode", "unified"),
                            )
                            tool_logs = []
                except Exception as e:
                    full_response = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    tool_logs = []

                response_placeholder.markdown(full_response)

                st.session_state.unified_messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "tool_logs": tool_logs
                })

                if st.session_state.get("report_panel_enabled") and chapter_order:
                    st.session_state.report_chapters[current_chapter] = full_response
                    st.session_state.report_edit_buffer = full_response
                    st.session_state.report_chapter_status[current_chapter] = "draft"
                    st.session_state.report_draft_content = _compose_full_draft(
                        st.session_state.report_chapters,
                        chapter_order,
                    )

                try:
                    current_team = st.session_state.get("current_team", "CIC ë´„ë‚ ")
                    current_conv_id = st.session_state.get("current_conversation_id")
                    new_conv_id = save_conversation(
                        current_team,
                        st.session_state.unified_messages,
                        conversation_id=current_conv_id
                    )
                    if not current_conv_id and new_conv_id:
                        st.session_state.current_conversation_id = new_conv_id
                except Exception as e:
                    logger.warning(f"ëŒ€í™” ìë™ ì €ì¥ ì‹¤íŒ¨: {e}")

        st.rerun()

# ========================================
# íŒ ë¡œí…Œì´ì…˜ ë°°ë„ˆ
# ========================================
st.markdown("""
<div class="loading-tips-banner">
    <span class="loading-tips-banner__icon">ğŸ’¡</span>
    <div class="loading-tips-banner__text"></div>
</div>

<script>
// íŒ ëª©ë¡
const tips = [
    "ğŸ’¡ 200ê°œ í•œ ë²ˆì— ì¶œë ¥í•´ë‹¬ë¼ê³  í•˜ì§€ ë§ˆì„¸ìš”. ìµœê·¼ 3-4ê°œì˜ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  ìˆì–´ì„œ ìµœëŒ€ 20ë§Œ í† í°ê¹Œì§€ë§Œ ì‘ë‹µì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
    "ğŸ“ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•œ í›„ ë¶„ì„ì„ ìš”ì²­í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "ğŸ¯ ë³µì¡í•œ ìš”ì²­ì€ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì£¼ì‹œë©´ ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "ğŸ” í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ ì‹œ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê²€ìƒ‰ ì •í™•ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.",
    "ğŸ“Š Exit í”„ë¡œì ì…˜ì€ íˆ¬ìê²€í†  ì—‘ì…€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.",
    "ğŸ¢ Peer ë¶„ì„ì€ ê¸°ì—…ì†Œê°œì„œ PDFë¥¼ ì²¨ë¶€í•´ì£¼ì„¸ìš”.",
    "ğŸ’¬ ìµœê·¼ ëŒ€í™”ë§Œ ê¸°ì–µí•˜ë¯€ë¡œ, ì´ì „ ë‚´ìš©ì„ ì°¸ì¡°í•˜ë ¤ë©´ ë‹¤ì‹œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.",
    "âš¡ ëŒ€í™”ê°€ 15ê°œ ì´ìƒ ìŒ“ì´ë©´ ìë™ìœ¼ë¡œ ì´ì „ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.",
    "ğŸ¨ 'ìƒˆ ëŒ€í™”' ë²„íŠ¼ìœ¼ë¡œ ì–¸ì œë“  ëŒ€í™”ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
];

let currentTipIndex = 0;

function rotateTips() {
    const tipElement = document.querySelector('.loading-tips-banner__text');
    if (tipElement) {
        // Fade out
        tipElement.style.opacity = '0';

        setTimeout(() => {
            // Change text
            tipElement.textContent = tips[currentTipIndex];
            currentTipIndex = (currentTipIndex + 1) % tips.length;

            // Fade in
            tipElement.style.opacity = '1';
        }, 500);
    }
}

// í˜ì´ì§€ ë¡œë“œ ì‹œ ì¦‰ì‹œ ì²« ë²ˆì§¸ íŒ í‘œì‹œ
setTimeout(() => {
    const tipElement = document.querySelector('.loading-tips-banner__text');
    if (tipElement) {
        tipElement.textContent = tips[0];
        tipElement.style.opacity = '1';
        currentTipIndex = 1;
    }
}, 100);

// 7ì´ˆë§ˆë‹¤ íŒ ë³€ê²½
setInterval(rotateTips, 7000);
</script>
""", unsafe_allow_html=True)

# ========================================
# í‘¸í„°
# ========================================
st.markdown("""
<div style="text-align: center; color: #9ca3af; font-size: 0.75rem; margin-top: 4rem; padding: 2rem 0; margin-bottom: 3rem;">
    Powered by Claude Opus 4.5 | ë©”ë¦¬ VC ì—ì´ì „íŠ¸ v2.0
</div>
""", unsafe_allow_html=True)
