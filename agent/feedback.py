"""
Feedback Collection & Reinforcement Learning System
ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° ê°•í™”í•™ìŠµ ì‹œìŠ¤í…œ
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

try:
    from .feedback_db import FeedbackDatabase
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False


class FeedbackSystem:
    """
    ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° ê°•í™”í•™ìŠµìš© ë°ì´í„° ìƒì„±

    í”¼ë“œë°± íƒ€ì…:
    - thumbs_up: ê¸ì •ì  í”¼ë“œë°± (ğŸ‘)
    - thumbs_down: ë¶€ì •ì  í”¼ë“œë°± (ğŸ‘)
    - text_feedback: í…ìŠ¤íŠ¸ í”¼ë“œë°± (ğŸ’¬)
    - correction: ìˆ˜ì • ìš”ì²­ (ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë‹µë³€ ì œê³µ)
    - rating: 1-5ì  í‰ì 
    """

    def __init__(self, storage_dir: str = "feedback", session_id: str = None, user_nickname: str = None, company_name: str = None):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)

        # í”¼ë“œë°± ë°ì´í„° íŒŒì¼
        self.feedback_file = self.storage_dir / "feedback_data.jsonl"

        # ê°•í™”í•™ìŠµìš© ë°ì´í„°ì…‹ íŒŒì¼
        self.rl_dataset_file = self.storage_dir / "rl_dataset.jsonl"

        # ë°ì´í„°ë² ì´ìŠ¤ (í†µí•© ê´€ë¦¬)
        self.db = FeedbackDatabase() if DB_AVAILABLE else None

        # ì„¸ì…˜ ì •ë³´
        self.session_id = session_id
        self.user_nickname = user_nickname
        self.company_name = company_name

    def add_feedback(
        self,
        user_message: str,
        assistant_response: str,
        feedback_type: str,
        feedback_value: Any = None,
        context: Dict[str, Any] = None
    ) -> str:
        """
        í”¼ë“œë°± ì¶”ê°€

        Args:
            user_message: ì‚¬ìš©ì ì§ˆë¬¸
            assistant_response: ì—ì´ì „íŠ¸ ì‘ë‹µ
            feedback_type: í”¼ë“œë°± íƒ€ì… (thumbs_up, thumbs_down, correction, rating)
            feedback_value: í”¼ë“œë°± ê°’ (correctionì¼ ê²½ìš° ì˜¬ë°”ë¥¸ ë‹µë³€, ratingì¼ ê²½ìš° ì ìˆ˜)
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (íŒŒì¼ ê²½ë¡œ, ë„êµ¬ ì‚¬ìš© ë“±)

        Returns:
            í”¼ë“œë°± ID
        """
        feedback_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")

        feedback_entry = {
            "id": feedback_id,
            "timestamp": datetime.now().isoformat(),
            "user_message": user_message,
            "assistant_response": assistant_response,
            "feedback_type": feedback_type,
            "feedback_value": feedback_value,
            "context": context or {},
            "metadata": {
                "message_length": len(assistant_response),
                "has_tool_use": bool(context and context.get("tools_used"))
            }
        }

        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥ (í•œ ì¤„ì— í•˜ë‚˜ì˜ JSON)
        with open(self.feedback_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(feedback_entry, ensure_ascii=False) + '\n')

        # ê°•í™”í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±
        self._generate_rl_data(feedback_entry)

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (í†µí•© ê´€ë¦¬)
        if self.db:
            reward = self._calculate_reward(feedback_type, feedback_value)
            self.db.add_feedback(
                feedback_id=feedback_id,
                session_id=self.session_id or "unknown",
                user_nickname=self.user_nickname or "anonymous",
                company_name=self.company_name or "unknown",
                user_message=user_message,
                assistant_response=assistant_response,
                feedback_type=feedback_type,
                reward=reward,
                feedback_value=feedback_value,
                context=context,
                metadata=feedback_entry["metadata"]
            )

        return feedback_id

    def _generate_rl_data(self, feedback_entry: Dict[str, Any]):
        """
        ê°•í™”í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± (OpenAI RLHF í˜•ì‹)

        Format:
        {
            "prompt": "ì‚¬ìš©ì ì§ˆë¬¸",
            "response": "ì—ì´ì „íŠ¸ ì‘ë‹µ",
            "reward": ì ìˆ˜ (-1 ~ 1),
            "context": {...},
            "timestamp": "..."
        }
        """
        # í”¼ë“œë°± íƒ€ì…ì— ë”°ë¼ ë³´ìƒ ì ìˆ˜ ê³„ì‚°
        reward = self._calculate_reward(
            feedback_entry["feedback_type"],
            feedback_entry.get("feedback_value")
        )

        rl_entry = {
            "prompt": feedback_entry["user_message"],
            "response": feedback_entry["assistant_response"],
            "reward": reward,
            "context": feedback_entry["context"],
            "feedback_id": feedback_entry["id"],
            "timestamp": feedback_entry["timestamp"],
            "metadata": feedback_entry["metadata"]
        }

        # Correctionì´ ìˆìœ¼ë©´ preferred_response ì¶”ê°€
        if feedback_entry["feedback_type"] == "correction":
            rl_entry["preferred_response"] = feedback_entry["feedback_value"]

        with open(self.rl_dataset_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(rl_entry, ensure_ascii=False) + '\n')

    def _calculate_reward(self, feedback_type: str, feedback_value: Any = None) -> float:
        """
        í”¼ë“œë°± íƒ€ì…ì— ë”°ë¥¸ ë³´ìƒ ì ìˆ˜ ê³„ì‚°

        Returns:
            -1.0 ~ 1.0 ì‚¬ì´ì˜ ë³´ìƒ ì ìˆ˜
        """
        reward_map = {
            "thumbs_up": 1.0,
            "thumbs_down": -1.0,
            "text_feedback": 0.0,  # ì¤‘ë¦½ (ë‚´ìš© ë¶„ì„ í•„ìš”)
            "rating": (feedback_value / 5.0 * 2) - 1 if feedback_value else 0.0,  # 1-5ì  â†’ -1~1
            "correction": -0.5  # ìˆ˜ì • ìš”ì²­ì€ ë¶€ì •ì  í”¼ë“œë°±
        }

        return reward_map.get(feedback_type, 0.0)

    def get_feedback_stats(self) -> Dict[str, Any]:
        """
        í”¼ë“œë°± í†µê³„ ìƒì„±

        Returns:
            {
                "total_feedback": ì „ì²´ í”¼ë“œë°± ìˆ˜,
                "positive_feedback": ê¸ì • í”¼ë“œë°± ìˆ˜,
                "negative_feedback": ë¶€ì • í”¼ë“œë°± ìˆ˜,
                "average_rating": í‰ê·  í‰ì ,
                "feedback_by_type": {...}
            }
        """
        if not self.feedback_file.exists():
            return {
                "total_feedback": 0,
                "positive_feedback": 0,
                "negative_feedback": 0,
                "average_rating": 0.0,
                "feedback_by_type": {}
            }

        feedbacks = []
        with open(self.feedback_file, 'r', encoding='utf-8') as f:
            for line in f:
                feedbacks.append(json.loads(line))

        total = len(feedbacks)
        positive = sum(1 for f in feedbacks if f["feedback_type"] == "thumbs_up")
        negative = sum(1 for f in feedbacks if f["feedback_type"] == "thumbs_down")

        ratings = [f["feedback_value"] for f in feedbacks if f["feedback_type"] == "rating" and f["feedback_value"]]
        avg_rating = sum(ratings) / len(ratings) if ratings else 0.0

        feedback_by_type = {}
        for f in feedbacks:
            ftype = f["feedback_type"]
            feedback_by_type[ftype] = feedback_by_type.get(ftype, 0) + 1

        return {
            "total_feedback": total,
            "positive_feedback": positive,
            "negative_feedback": negative,
            "average_rating": avg_rating,
            "feedback_by_type": feedback_by_type,
            "satisfaction_rate": positive / total if total > 0 else 0.0
        }

    def export_rl_dataset(self, format: str = "jsonl") -> str:
        """
        ê°•í™”í•™ìŠµìš© ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸°

        Args:
            format: ì¶œë ¥ í˜•ì‹ ("jsonl", "csv", "parquet")

        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        if not self.rl_dataset_file.exists():
            return None

        if format == "jsonl":
            return str(self.rl_dataset_file)

        # CSV ë³€í™˜
        elif format == "csv":
            import csv

            output_file = self.storage_dir / "rl_dataset.csv"

            with open(self.rl_dataset_file, 'r', encoding='utf-8') as f_in:
                entries = [json.loads(line) for line in f]

            if not entries:
                return None

            with open(output_file, 'w', newline='', encoding='utf-8') as f_out:
                writer = csv.DictWriter(f_out, fieldnames=entries[0].keys())
                writer.writeheader()
                writer.writerows(entries)

            return str(output_file)

        return str(self.rl_dataset_file)

    def get_recent_feedback(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ í”¼ë“œë°± ê°€ì ¸ì˜¤ê¸°

        Args:
            limit: ê°€ì ¸ì˜¬ í”¼ë“œë°± ìˆ˜

        Returns:
            ìµœê·¼ í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸
        """
        if not self.feedback_file.exists():
            return []

        feedbacks = []
        with open(self.feedback_file, 'r', encoding='utf-8') as f:
            for line in f:
                feedbacks.append(json.loads(line))

        return feedbacks[-limit:]

    def analyze_feedback_patterns(self) -> Dict[str, Any]:
        """
        í”¼ë“œë°± íŒ¨í„´ ë¶„ì„

        Returns:
            {
                "common_issues": [...],  # ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œ
                "high_performing_patterns": [...],  # ë†’ì€ í‰ê°€ë¥¼ ë°›ëŠ” íŒ¨í„´
                "improvement_areas": [...]  # ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­
            }
        """
        if not self.feedback_file.exists():
            return {
                "common_issues": [],
                "high_performing_patterns": [],
                "improvement_areas": []
            }

        feedbacks = []
        with open(self.feedback_file, 'r', encoding='utf-8') as f:
            for line in f:
                feedbacks.append(json.loads(line))

        # ë¶€ì •ì  í”¼ë“œë°± íŒ¨í„´ ë¶„ì„
        negative_feedbacks = [f for f in feedbacks if f["feedback_type"] in ["thumbs_down", "correction"]]

        common_issues = []
        if negative_feedbacks:
            # ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë³„ ì‹¤íŒ¨ìœ¨
            tool_failures = sum(1 for f in negative_feedbacks if f["metadata"].get("has_tool_use"))
            common_issues.append({
                "issue": "ë„êµ¬ ì‚¬ìš© ì‹œ ì˜¤ë¥˜",
                "count": tool_failures,
                "percentage": tool_failures / len(negative_feedbacks) * 100
            })

        # ê¸ì •ì  í”¼ë“œë°± íŒ¨í„´ ë¶„ì„
        positive_feedbacks = [f for f in feedbacks if f["feedback_type"] == "thumbs_up"]

        high_performing_patterns = []
        if positive_feedbacks:
            # ì‘ë‹µ ê¸¸ì´ ë¶„ì„
            avg_length = sum(f["metadata"]["message_length"] for f in positive_feedbacks) / len(positive_feedbacks)
            high_performing_patterns.append({
                "pattern": "ìµœì  ì‘ë‹µ ê¸¸ì´",
                "value": f"{avg_length:.0f}ì"
            })

        # ê°œì„  ì˜ì—­
        improvement_areas = []
        stats = self.get_feedback_stats()

        if stats["satisfaction_rate"] < 0.7:
            improvement_areas.append({
                "area": "ì „ì²´ ë§Œì¡±ë„",
                "current": f"{stats['satisfaction_rate']*100:.1f}%",
                "target": "70% ì´ìƒ"
            })

        return {
            "common_issues": common_issues,
            "high_performing_patterns": high_performing_patterns,
            "improvement_areas": improvement_areas
        }
