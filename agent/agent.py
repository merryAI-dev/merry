"""Conversational VC Investment Agent"""

import os
from typing import AsyncIterator, Dict, Any, List
from dotenv import load_dotenv

# TODO: Migrate to Claude Agent SDK when available on PyPI
# from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions
from anthropic import Anthropic, AsyncAnthropic

from .tools import register_tools, execute_tool

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class AgentContext:
    """ì—ì´ì „íŠ¸ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ (ë©”ëª¨ë¦¬)"""

    def __init__(self):
        self.analyzed_files: List[str] = []
        self.cached_results: Dict[str, Any] = {}
        self.user_preferences: Dict[str, Any] = {}

    def remember(self, key: str, value: Any):
        """ì •ë³´ ê¸°ì–µ"""
        self.cached_results[key] = value

    def recall(self, key: str) -> Any:
        """ì •ë³´ íšŒìƒ"""
        return self.cached_results.get(key)

    def add_analyzed_file(self, file_path: str):
        """ë¶„ì„í•œ íŒŒì¼ ê¸°ë¡"""
        if file_path not in self.analyzed_files:
            self.analyzed_files.append(file_path)


class ConversationalVCAgent:
    """ìì—°ì–´ë¡œ ì†Œí†µ ê°€ëŠ¥í•œ VC íˆ¬ì ë¶„ì„ ì—ì´ì „íŠ¸"""

    def __init__(self, api_key: str = None, model: str = "claude-sonnet-4"):
        """
        Args:
            api_key: Anthropic API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            model: ì‚¬ìš©í•  ëª¨ë¸ (claude-sonnet-4, claude-opus-4 ë“±)
        """
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")

        if not self.api_key:
            raise ValueError(
                "ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”."
            )

        # Using Anthropic SDK (will migrate to Claude Agent SDK when available)
        self.client = Anthropic(api_key=self.api_key)
        self.async_client = AsyncAnthropic(api_key=self.api_key)
        self.model = model

        # ë„êµ¬ ë“±ë¡
        self.tools = register_tools()

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (for session continuity)
        self.conversation_history: List[Dict[str, Any]] = []

        # ì»¨í…ìŠ¤íŠ¸ (ë©”ëª¨ë¦¬)
        self.context = AgentContext()

    def _build_system_prompt(self) -> str:
        """ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        analyzed_files_str = ", ".join(self.context.analyzed_files) if self.context.analyzed_files else "ì—†ìŒ"

        return f"""ë‹¹ì‹ ì€ VC íˆ¬ì ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ë„êµ¬ë¥¼ ì¡°í•©í•˜ì—¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## í˜„ì¬ ì»¨í…ìŠ¤íŠ¸
- ë¶„ì„ëœ íŒŒì¼: {analyzed_files_str}
- ìºì‹œëœ ê²°ê³¼: {len(self.context.cached_results)}ê°œ

## ëŠ¥ë ¥
1. **ìœ ì—°í•œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„**: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì–´ë–¤ ì¡°í•©ì˜ ì‹œë‚˜ë¦¬ì˜¤ë„ ë¶„ì„ ê°€ëŠ¥
   - í‘œì¤€ ì‹œë‚˜ë¦¬ì˜¤: ì „ì²´ ë§¤ê°, ë¶€ë¶„ ë§¤ê°, SAFE ì „í™˜, ì½œì˜µì…˜
   - ë§ì¶¤ ì‹œë‚˜ë¦¬ì˜¤: ì‚¬ìš©ìê°€ ì •ì˜í•œ ë…íŠ¹í•œ êµ¬ì¡°

2. **ë‹¤ì–‘í•œ ë°¸ë¥˜ì—ì´ì…˜ ë°©ë²•ë¡ **
   - PER, EV/Revenue, EV/EBITDA ë“± ëª¨ë“  ë°©ë²•ë¡  ì§€ì›
   - í˜¼í•© ë°©ì‹ë„ ê°€ëŠ¥ (ì˜ˆ: 2029ë…„ì€ PER, 2030ë…„ì€ EV/Revenue)

3. **ë³µì¡í•œ í¬ì„ êµ¬ì¡°**
   - SAFE, ì½œì˜µì…˜, ì‹ ê·œ íˆ¬ì ë¼ìš´ë“œ ë“±
   - ë‹¤ë‹¨ê³„ íˆ¬ì ë¼ìš´ë“œ ì‹œë®¬ë ˆì´ì…˜

4. **ë§ì¶¤í˜• Exit ì‹œë‚˜ë¦¬ì˜¤**
   - 2ë‹¨ê³„, 3ë‹¨ê³„, Në‹¨ê³„ ë§¤ê°
   - ì‹œê°„ì— ë”°ë¥¸ ê°€ì¹˜ ë³€í™” ë°˜ì˜

## ì‘ì—… ë°©ì‹
1. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ ì´í•´
2. í•„ìš”í•œ ë°ì´í„° í™•ì¸ (ì—†ìœ¼ë©´ ì§ˆë¬¸)
3. ì ì ˆí•œ ë„êµ¬ ì¡°í•©ìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
4. ê²°ê³¼ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…
5. ì¶”ê°€ ë¶„ì„ì´ë‚˜ ìˆ˜ì •ì‚¬í•­ ì œì•ˆ

## ì¤‘ìš” ì›ì¹™
- **ì ˆëŒ€ ê³ ì •ëœ í‹€ì— ë§ì¶”ì§€ ë§ˆì„¸ìš”**: "ì´ê±´ basic/advanced/complete ì¤‘ í•˜ë‚˜"ê°€ ì•„ë‹™ë‹ˆë‹¤
- **ì‚¬ìš©ì ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”**: "ë¶€ë¶„ ë§¤ê°"ì´ë¼ê³  í•˜ë©´ ë¹„ìœ¨ê³¼ ì‹œì ì„ ë¬¼ì–´ë³´ì„¸ìš”
- **ì°½ì˜ì ìœ¼ë¡œ ì¡°í•©í•˜ì„¸ìš”**: ê¸°ì¡´ì— ì—†ë˜ ì‹œë‚˜ë¦¬ì˜¤ë„ ë„êµ¬ë¥¼ ì¡°í•©í•´ ë¶„ì„í•˜ì„¸ìš”
- **í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”**: ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”

## ë„êµ¬ ì‚¬ìš© ê°€ì´ë“œ
- `analyze_excel`: ì—‘ì…€ íŒŒì¼ ë¶„ì„ (ì²« ë‹¨ê³„)
- `calculate_valuation`: ê¸°ì—…ê°€ì¹˜ ê³„ì‚° (PER, EV/Revenue ë“±)
- `calculate_dilution`: ì§€ë¶„ í¬ì„ ê³„ì‚° (SAFE, ì‹ ê·œ ë¼ìš´ë“œ ë“±)
- `calculate_irr`: IRRê³¼ ë©€í‹°í”Œ ê³„ì‚°
- `generate_exit_projection`: ìµœì¢… ì—‘ì…€ íŒŒì¼ ìƒì„±

## ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°
1. ì‚¬ìš©ì: "ë¹„ì‚¬ì´ë“œë¯¸ íˆ¬ì ë¶„ì„í•´ì¤˜"
   â†’ analyze_excel ì‚¬ìš©

2. ì‚¬ìš©ì: "2029ë…„ PER 15ë¡œ Exit ì‹œ IRRì€?"
   â†’ calculate_valuation â†’ calculate_irr

3. ì‚¬ìš©ì: "SAFE 1ì–µ ì¶”ê°€ë˜ë©´ í¬ì„ ì–¼ë§ˆ?"
   â†’ calculate_dilution

4. ì‚¬ìš©ì: "ì—‘ì…€ë¡œ ë§Œë“¤ì–´ì¤˜"
   â†’ generate_exit_projection
"""

    async def chat(self, user_message: str) -> AsyncIterator[str]:
        """
        ìì—°ì–´ ëŒ€í™” ì¸í„°í˜ì´ìŠ¤ (ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Yields:
            str: ì—ì´ì „íŠ¸ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
        """

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = self._build_system_prompt()

        # Claude API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
        async with self.async_client.messages.stream(
            model=self.model,
            system=system_prompt,
            messages=self.conversation_history,
            tools=self.tools,
            max_tokens=4096
        ) as stream:

            assistant_content = []

            async for event in stream:
                # í…ìŠ¤íŠ¸ ì¶œë ¥
                if event.type == "content_block_delta":
                    if hasattr(event.delta, 'text'):
                        text = event.delta.text
                        assistant_content.append({"type": "text", "text": text})
                        yield text

                # ë„êµ¬ ì‚¬ìš©
                elif event.type == "content_block_stop":
                    message = await stream.get_final_message()

                    # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
                    tool_results = []
                    for content_block in message.content:
                        if content_block.type == "tool_use":
                            tool_name = content_block.name
                            tool_input = content_block.input

                            yield f"\n\nğŸ”§ **ë„êµ¬ ì‚¬ìš©: {tool_name}**\n"

                            # ë„êµ¬ ì‹¤í–‰
                            tool_result = execute_tool(tool_name, tool_input)

                            # ê²°ê³¼ ì €ì¥
                            tool_results.append({
                                "type": "tool_result",
                                "tool_use_id": content_block.id,
                                "content": str(tool_result)
                            })

                            # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                            if tool_name == "analyze_excel" and tool_result.get("success"):
                                self.context.add_analyzed_file(tool_input.get("excel_path"))
                                self.context.remember("last_analysis", tool_result)

                            yield f"âœ… ì™„ë£Œ\n\n"

                    # ë„êµ¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ëŒ€í™”ì— ì¶”ê°€í•˜ê³  ê³„ì† ì§„í–‰
                    if tool_results:
                        # Assistant ë©”ì‹œì§€ ì¶”ê°€
                        self.conversation_history.append({
                            "role": "assistant",
                            "content": message.content
                        })

                        # Tool ê²°ê³¼ ì¶”ê°€
                        self.conversation_history.append({
                            "role": "user",
                            "content": tool_results
                        })

                        # Claudeê°€ ë‹¤ìŒ ì‘ë‹µ ìƒì„±
                        async for continuation_text in self._continue_conversation():
                            yield continuation_text

    async def _continue_conversation(self) -> AsyncIterator[str]:
        """ë„êµ¬ ì‹¤í–‰ í›„ ëŒ€í™” ê³„ì†"""

        system_prompt = self._build_system_prompt()

        async with self.async_client.messages.stream(
            model=self.model,
            system=system_prompt,
            messages=self.conversation_history,
            tools=self.tools,
            max_tokens=4096
        ) as stream:

            async for event in stream:
                if event.type == "content_block_delta":
                    if hasattr(event.delta, 'text'):
                        yield event.delta.text

    def chat_sync(self, user_message: str) -> str:
        """
        ë™ê¸° ë²„ì „ (ê°„ë‹¨í•œ ì‚¬ìš©)

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            str: ì—ì´ì „íŠ¸ ì‘ë‹µ (ì „ì²´)
        """
        import asyncio

        # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ë¡œ ì‹¤í–‰
        async def async_chat():
            response_text = ""
            async for chunk in self.chat(user_message):
                response_text += chunk
            return response_text

        loop = asyncio.get_event_loop()
        return loop.run_until_complete(async_chat())

    def reset(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.conversation_history = []
        self.context = AgentContext()
