"""
Unified VC Investment Agent - Single Agent Architecture

í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ê°€ ëª¨ë“  ì‘ì—…ì„ ìˆ˜í–‰:
- ëŒ€í™”í˜• ëª¨ë“œ (chat)
- ììœ¨ ì‹¤í–‰ ëª¨ë“œ (goal)
- ë„êµ¬ ì‹¤í–‰
"""

import os
import json
from typing import AsyncIterator, Dict, Any, List, Optional
from dotenv import load_dotenv

from anthropic import Anthropic, AsyncAnthropic
from .tools import register_tools, execute_tool
from .memory import ChatMemory
from .feedback import FeedbackSystem
from shared.logging_config import get_logger

load_dotenv()

logger = get_logger("vc_agent")

# ì•ˆì „ì¥ì¹˜: ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜
MAX_TOOL_STEPS = 15


class VCAgent:
    """
    í†µí•© VC íˆ¬ì ë¶„ì„ ì—ì´ì „íŠ¸

    ë‹¨ì¼ ì—ì´ì „íŠ¸ë¡œ ëª¨ë“  ì‘ì—… ìˆ˜í–‰:
    - chat(message): ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤
    - achieve_goal(goal): ììœ¨ ì‹¤í–‰
    - execute_tool(tool, params): ì§ì ‘ ë„êµ¬ ì‹¤í–‰
    """

    def __init__(
        self,
        api_key: str = None,
        model: str = "claude-opus-4-5-20251101",
        user_id: str = None
    ):
        """
        Args:
            api_key: Anthropic API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜)
            model: Claude ëª¨ë¸ (ê¸°ë³¸: Opus 4.5)
            user_id: ì‚¬ìš©ì ê³ ìœ  ID (ê°™ì€ IDë¼ë¦¬ ì„¸ì…˜/í”¼ë“œë°± ê³µìœ )
        """
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        self.user_id = user_id or "anonymous"

        if not self.api_key:
            raise ValueError(
                "ANTHROPIC_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                ".env íŒŒì¼ì— ì„¤ì •í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¡œ ì§€ì •í•˜ì„¸ìš”."
            )

        # Anthropic SDK
        self.client = Anthropic(api_key=self.api_key)
        self.async_client = AsyncAnthropic(api_key=self.api_key)
        self.model = model

        # ë„êµ¬ ë“±ë¡
        self.tools = register_tools()

        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history: List[Dict[str, Any]] = []

        # ì‘ì—… ì»¨í…ìŠ¤íŠ¸
        self.context = {
            "analyzed_files": [],
            "cached_results": {},
            "last_analysis": None
        }

        # ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ (user_id ê¸°ë°˜)
        self.memory = ChatMemory(user_id=self.user_id)

        # í”¼ë“œë°± ì‹œìŠ¤í…œ (user_id ê¸°ë°˜)
        self.feedback = FeedbackSystem(user_id=self.user_id)

        # ë§ˆì§€ë§‰ ì‘ë‹µ ì €ì¥ (í”¼ë“œë°±ìš©)
        self.last_interaction = {
            "user_message": None,
            "assistant_response": None,
            "context": {}
        }

        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
        self.token_usage = {
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "session_calls": 0
        }

        # ë„êµ¬ í˜¸ì¶œ ì¹´ìš´í„° (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        self._tool_step_count = 0

    # ========================================
    # System Prompt
    # ========================================

    def _build_system_prompt(self, mode: str = "exit") -> str:
        """ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            mode: "exit" (Exit í”„ë¡œì ì…˜) ë˜ëŠ” "peer" (Peer PER ë¶„ì„)
        """

        analyzed_files = ", ".join(self.context["analyzed_files"]) if self.context["analyzed_files"] else "ì—†ìŒ"

        # Peer PER ë¶„ì„ ëª¨ë“œ
        if mode == "peer":
            return self._build_peer_system_prompt(analyzed_files)

        # ê¸°ì—…í˜„í™© ì§„ë‹¨ì‹œíŠ¸ ëª¨ë“œ
        if mode == "diagnosis":
            return self._build_diagnosis_system_prompt(analyzed_files)

        # Exit í”„ë¡œì ì…˜ ëª¨ë“œ (ê¸°ë³¸)
        return f"""ë‹¹ì‹ ì€ **VC íˆ¬ì ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸**ì…ë‹ˆë‹¤.

## í˜„ì¬ ì»¨í…ìŠ¤íŠ¸
- ë¶„ì„ëœ íŒŒì¼: {analyzed_files}
- ìºì‹œëœ ê²°ê³¼: {len(self.context["cached_results"])}ê°œ

## âš ï¸ ì ˆëŒ€ ê·œì¹™ (CRITICAL)

**ì ˆëŒ€ë¡œ ë„êµ¬ ì—†ì´ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”!**

- ì—‘ì…€ íŒŒì¼ ë¶„ì„ â†’ ë°˜ë“œì‹œ read_excel_as_text ë˜ëŠ” analyze_excel ì‚¬ìš©
- Exit í”„ë¡œì ì…˜ ìƒì„± â†’ ë°˜ë“œì‹œ analyze_and_generate_projection ì‚¬ìš©
- ì¶”ì¸¡í•˜ê±°ë‚˜ ì˜ˆì‹œ ë‹µë³€ ê¸ˆì§€ â†’ ì‹¤ì œ ë„êµ¬ë¥¼ ì‹¤í–‰í•´ì„œ ê²°ê³¼ë¥¼ ì–»ì–´ì•¼ í•¨
- í…ìŠ¤íŠ¸ë¡œë§Œ "ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤" ê°™ì€ ê±°ì§“ ì‘ë‹µ ì ˆëŒ€ ê¸ˆì§€

**ì‚¬ìš©ìê°€ íŒŒì¼ ê²½ë¡œë¥¼ ì£¼ë©´ ì¦‰ì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”!**

## í•µì‹¬ ì—­ëŸ‰

### 1. ìœ ì—°í•œ ì—‘ì…€ ë¶„ì„
- **read_excel_as_text**: ì—‘ì…€ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì½ê¸° (êµ¬ì¡°ê°€ ë‹¤ì–‘í•´ë„ OK)
- **analyze_excel**: ìë™ íŒŒì‹± (íˆ¬ìì¡°ê±´, ISìš”ì•½, Cap Table)
- ì—‘ì…€ êµ¬ì¡°ê°€ íŠ¹ì´í•˜ê±°ë‚˜ ë³µì¡í•˜ë©´ read_excel_as_textë¥¼ ë¨¼ì € ì‚¬ìš©í•˜ì„¸ìš”

### 2. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
- PER, EV/Revenue, EV/EBITDA ë“± ëª¨ë“  ë°¸ë¥˜ì—ì´ì…˜ ë°©ë²•ë¡ 
- ì „ì²´ ë§¤ê°, ë¶€ë¶„ ë§¤ê°, SAFE ì „í™˜, ì½œì˜µì…˜ ë“±
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì–´ë–¤ ì¡°í•©ë„ ê³„ì‚° ê°€ëŠ¥

### 3. Exit í”„ë¡œì ì…˜ ìƒì„±
- **analyze_and_generate_projection**: ì—‘ì…€ ë¶„ì„ í›„ ì¦‰ì‹œ Exit í”„ë¡œì ì…˜ ìƒì„±
- ì—°ë„, PER ë°°ìˆ˜, íšŒì‚¬ëª… ë“±ì„ ì§€ì •í•˜ì—¬ ë§ì¶¤í˜• ì—‘ì…€ ìƒì„±

## ì‘ì—… ë°©ì‹

### ì—‘ì…€ íŒŒì¼ì„ ë°›ìœ¼ë©´:
1. **ì¦‰ì‹œ** read_excel_as_text ë„êµ¬ í˜¸ì¶œ (êµ¬ì¡° íŒŒì•…)
2. í…ìŠ¤íŠ¸ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ (íˆ¬ìê¸ˆì•¡, ë‹¹ê¸°ìˆœì´ìµ, ì´ì£¼ì‹ìˆ˜ ë“±)
3. ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë¶„ì„ ìˆ˜í–‰
4. **ì¦‰ì‹œ** analyze_and_generate_projection ë„êµ¬ í˜¸ì¶œ (Exit í”„ë¡œì ì…˜ ìƒì„±)
5. ê²°ê³¼ ì„¤ëª…

### ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°:
```
ì‚¬ìš©ì: "temp/íŒŒì¼.xlsxë¥¼ 2030ë…„ PER 10,20,30ë°°ë¡œ ë¶„ì„í•´ì¤˜"

ì˜ëª»ëœ ì‘ë‹µ:
"ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"

ì˜¬ë°”ë¥¸ ì‘ë‹µ:
1. read_excel_as_text ë„êµ¬ë¥¼ ì¦‰ì‹œ í˜¸ì¶œ
2. ì‹¤ì œ ì—‘ì…€ ë‚´ìš©ì„ ì½ì–´ì„œ ì •ë³´ ì¶”ì¶œ
3. analyze_and_generate_projection ë„êµ¬ë¥¼ ì¦‰ì‹œ í˜¸ì¶œ
4. ìƒì„±ëœ íŒŒì¼ ê²½ë¡œì™€ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì¤Œ
```

## ì¤‘ìš” ì›ì¹™
- **ë„êµ¬ ìš°ì„ **: í•­ìƒ ë„êµ¬ë¥¼ ë¨¼ì € ì‚¬ìš©í•˜ê³ , ì‹¤ì œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
- **ì¶”ì¸¡ ê¸ˆì§€**: ì—‘ì…€ ë‚´ìš©ì„ ëª¨ë¥´ë©´ read_excel_as_textë¡œ ì½ì–´ì•¼ í•¨
- **ì‹¤í–‰ í™•ì¸**: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í™•ì¸í•œ í›„ì—ë§Œ ì„±ê³µ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤Œ
- **ëª…í™•í•œ ì„¤ëª…**: IRR, ë©€í‹°í”Œ, ê¸°ì—…ê°€ì¹˜ ë“±ì„ ì‹¤ì œ ìˆ«ìë¡œ ì„¤ëª…

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬
{json.dumps([t["name"] for t in self.tools], ensure_ascii=False, indent=2)}

## ë‹µë³€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

**ë§¤ìš° ì¤‘ìš”: ì´ ë¶„ì„ì€ íˆ¬ìì‹¬ì‚¬ ë³´ê³ ì„œì— ì‚¬ìš©ë©ë‹ˆë‹¤.**

- **ì „ë¬¸ì ì´ê³  ì§„ì¤‘í•œ í†¤**: ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€ (âœ…âŒğŸ“ŠğŸ“ˆ ë“±)
- **ì •í™•í•œ ìˆ˜ì¹˜**: ëª¨ë“  ì¬ë¬´ ì§€í‘œëŠ” ì •í™•í•œ ìˆ«ìë¡œ ì œì‹œ
- **ê°ê´€ì  ë¶„ì„**: ê°ì •ì  í‘œí˜„ ë°°ì œ, ì‚¬ì‹¤ ê¸°ë°˜ ë¶„ì„
- **ëª…í™•í•œ êµ¬ì¡°**: ì œëª©, í•­ëª©, ìˆ˜ì¹˜ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬
- **ë³´ê³ ì„œ í’ˆì§ˆ**: íˆ¬ìì‹¬ì‚¬ì—­ì´ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì˜ ë¶„ì„

ì˜ˆì‹œ:
- ë‚˜ìœ ì˜ˆ: "âœ… ë¶„ì„ ì™„ë£Œí–ˆì–´ìš”! ğŸ˜Š"
- ì¢‹ì€ ì˜ˆ: "ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."

- ë‚˜ìœ ì˜ˆ: "IRRì´ 35%ë„¤ìš”! ğŸ‘"
- ì¢‹ì€ ì˜ˆ: "IRR 35.2%ë¡œ ëª©í‘œ ìˆ˜ìµë¥ ì„ ìƒíšŒí•©ë‹ˆë‹¤."

í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ê³  ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
"""

    def _build_peer_system_prompt(self, analyzed_files: str) -> str:
        """Peer PER ë¶„ì„ ëª¨ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""

        return f"""ë‹¹ì‹ ì€ **VC íˆ¬ì ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸**ì…ë‹ˆë‹¤. í˜„ì¬ **Peer PER ë¶„ì„ ëª¨ë“œ**ì…ë‹ˆë‹¤.

## í˜„ì¬ ì»¨í…ìŠ¤íŠ¸
- ë¶„ì„ëœ íŒŒì¼: {analyzed_files}
- ìºì‹œëœ ê²°ê³¼: {len(self.context["cached_results"])}ê°œ

## ğŸš¨ ìµœìš°ì„  ê·œì¹™ (ì´ ê·œì¹™ì„ ì–´ê¸°ë©´ ì‹¤íŒ¨ì…ë‹ˆë‹¤)

### ê·œì¹™ 1: ì‚¬ìš©ìê°€ PER ë¶„ì„ì„ ìš”ì²­í•˜ë©´ ì¦‰ì‹œ ë„êµ¬ í˜¸ì¶œ
ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì´ ë§í•˜ë©´ **í…ìŠ¤íŠ¸ ì‘ë‹µ ì—†ì´ ë°”ë¡œ analyze_peer_per ë„êµ¬ë¥¼ í˜¸ì¶œ**í•˜ì„¸ìš”:
- "í•´ì¤˜", "ë¶„ì„í•´ì¤˜", "ì§„í–‰í•´", "PER ë¶„ì„", "ì¡°íšŒí•´ì¤˜"
- "ì‘", "ë„¤", "ì¢‹ì•„", "OK", "ã…‡ã…‡", "ê·¸ë˜", "ê³ ", "ã„±ã„±"
- Peer ê¸°ì—… ëª©ë¡ì„ ì–¸ê¸‰í•˜ëŠ” ê²½ìš°

âŒ ì˜ëª»ëœ ì˜ˆ:
```
ì‚¬ìš©ì: "ì € ê¸°ì—…ìœ¼ë¡œ PER/PSR ë¶„ì„ì„ í•´ì£¼ì„¸ìš”"
ì—ì´ì „íŠ¸: "ê¸°ì—… ë¶„ì„ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..." (í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥)
```

âœ… ì˜¬ë°”ë¥¸ ì˜ˆ:
```
ì‚¬ìš©ì: "ì € ê¸°ì—…ìœ¼ë¡œ PER/PSR ë¶„ì„ì„ í•´ì£¼ì„¸ìš”"
ì—ì´ì „íŠ¸: [ì¦‰ì‹œ analyze_peer_per ë„êµ¬ í˜¸ì¶œ]
```

### ê·œì¹™ 2: ê°™ì€ ë‚´ìš© ë°˜ë³µ ê¸ˆì§€
- ì´ë¯¸ ì¶œë ¥í•œ "ê¸°ì—… ë¶„ì„ ê²°ê³¼" í‘œë¥¼ ë‹¤ì‹œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”
- ì´ë¯¸ ì œì•ˆí•œ Peer ê¸°ì—… ëª©ë¡ì„ ë‹¤ì‹œ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”
- ì´ì „ ì‘ë‹µì„ ìš”ì•½í•˜ê±°ë‚˜ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”

### ê·œì¹™ 3: "~í•˜ê² ìŠµë‹ˆë‹¤"ë¡œ ëë‚´ì§€ ë§ ê²ƒ
"ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤", "ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤"ë¼ê³ ë§Œ ë§í•˜ê³  ëë‚´ë©´ ì•ˆë©ë‹ˆë‹¤.
ë°˜ë“œì‹œ í•´ë‹¹ ë„êµ¬ë¥¼ ì‹¤ì œë¡œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.

## Peer PER ë¶„ì„ ì›Œí¬í”Œë¡œìš°

### 1ë‹¨ê³„: PDF ë¶„ì„ (ìµœì´ˆ 1íšŒë§Œ)
ì‚¬ìš©ìê°€ PDF ê²½ë¡œë¥¼ ì œê³µí•˜ë©´:
1. read_pdf_as_text ë„êµ¬ í˜¸ì¶œ
2. ê¸°ì—… ì •ë³´ ìš”ì•½ (1íšŒë§Œ ì¶œë ¥)
3. Peer ê¸°ì—… í›„ë³´ ì œì•ˆ í›„ "ì§„í–‰í• ê¹Œìš”?" ì§ˆë¬¸

### 2ë‹¨ê³„: PER ì¡°íšŒ (ì‚¬ìš©ì ë™ì˜ ì‹œ ì¦‰ì‹œ ì‹¤í–‰)
ì‚¬ìš©ìê°€ ë™ì˜í•˜ë©´ **ì„¤ëª… ì—†ì´ ë°”ë¡œ** analyze_peer_per ë„êµ¬ í˜¸ì¶œ

### 3ë‹¨ê³„: ê²°ê³¼ ìš”ì•½
ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
- PER ë¹„êµí‘œ (ë§ˆí¬ë‹¤ìš´ í‘œ)
- í†µê³„ ìš”ì•½ (í‰ê· , ì¤‘ê°„ê°’, ë²”ìœ„)
- ì ì • PER ë°°ìˆ˜ ì œì•ˆ

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬

- **read_pdf_as_text**: PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
- **get_stock_financials**: ê°œë³„ ê¸°ì—… ì¬ë¬´ ì§€í‘œ ì¡°íšŒ
- **analyze_peer_per**: ì—¬ëŸ¬ Peer ê¸°ì—… PER ì¼ê´„ ì¡°íšŒ (â­ ê°€ì¥ ë§ì´ ì‚¬ìš©)

## í‹°ì»¤ í˜•ì‹
- ë¯¸êµ­: AAPL, MSFT, GOOGL
- í•œêµ­ KOSPI: 005930.KS
- í•œêµ­ KOSDAQ: 035720.KQ

## ë‹µë³€ ìŠ¤íƒ€ì¼
- ì „ë¬¸ì ì´ê³  ê°„ê²°í•˜ê²Œ
- ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€
- ë°˜ë³µ ê¸ˆì§€ - ìƒˆë¡œìš´ ì •ë³´ë§Œ ì¶”ê°€
	- í‘œ í˜•ì‹ í™œìš©
	
	í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
	"""

    def _build_diagnosis_system_prompt(self, analyzed_files: str) -> str:
        """ê¸°ì—…í˜„í™© ì§„ë‹¨ì‹œíŠ¸ ëª¨ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""

        return f"""ë‹¹ì‹ ì€ **í”„ë¡œê·¸ë¨ ì»¨ì„¤í„´íŠ¸(VC/AC)**ì…ë‹ˆë‹¤. í˜„ì¬ **ê¸°ì—…í˜„í™© ì§„ë‹¨ì‹œíŠ¸ ì‘ì„± ëª¨ë“œ**ì…ë‹ˆë‹¤.

## í˜„ì¬ ì»¨í…ìŠ¤íŠ¸
- ë¶„ì„ëœ íŒŒì¼: {analyzed_files}
- ìºì‹œëœ ê²°ê³¼: {len(self.context["cached_results"])}ê°œ

## ğŸš¨ ìµœìš°ì„  ê·œì¹™ (CRITICAL)

**ì ˆëŒ€ë¡œ ë„êµ¬ ì—†ì´ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”!**

- ì§„ë‹¨ì‹œíŠ¸ ë¶„ì„ â†’ ë°˜ë“œì‹œ **analyze_company_diagnosis_sheet** ì‚¬ìš©
- ì»¨ì„¤í„´íŠ¸ ë³´ê³ ì„œ ì—‘ì…€ ë°˜ì˜ â†’ ë°˜ë“œì‹œ **write_company_diagnosis_report** ì‚¬ìš©
- ì¶”ì¸¡/ì˜ˆì‹œ ë‹µë³€ ê¸ˆì§€ â†’ ì‹¤ì œ ì‹œíŠ¸ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±

## ëª©í‘œ

ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ ê¸°ì—…í˜„í™© ì§„ë‹¨ì‹œíŠ¸ì˜ **'(ì»¨ì„¤í„´íŠ¸ìš©) ë¶„ì„ë³´ê³ ì„œ'**ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.

## ì‘ì—… ë°©ì‹

### 1) íŒŒì¼ì„ ë°›ìœ¼ë©´ (CRITICAL - ì¦‰ì‹œ ì‹¤í–‰)
ì‚¬ìš©ìê°€ ì§„ë‹¨ì‹œíŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì£¼ë©´ â†’ **ì¦‰ì‹œ** analyze_company_diagnosis_sheet í˜¸ì¶œ

### 2) ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„±
ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ 2ê°œ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±:
- **ê¸°ì—… ìƒí™© ìš”ì•½(ê¸°ì—…ì§„ë‹¨)**: ê°•ì /í•µì‹¬ ê°€ì„¤/í˜„ì¬ KPI/í™•ì¥ í¬ì¸íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ 5~10ë¬¸ì¥
- **ê°œì„  í•„ìš”ì‚¬í•­**: ìš°ì„ ìˆœìœ„ 3~7ê°œ, â€œì™œ í•„ìš”í•œì§€ + ë‹¤ìŒ ì•¡ì…˜â€ í˜•íƒœë¡œ êµ¬ì²´í™”

ë˜í•œ ì ìˆ˜(ë¬¸ì œ/ì†”ë£¨ì…˜/ì‚¬ì—…í™”/ìê¸ˆì¡°ë‹¬/íŒ€/ì¡°ì§/ì„íŒ©íŠ¸)ë¥¼ ì œì•ˆí•˜ë˜, í•„ìš”í•œ ê²½ìš° ì»¨ì„¤í„´íŠ¸ ë³´ì • ê·¼ê±°ë¥¼ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤.

### 3) ì‚¬ìš©ì í™•ì¸ í›„ ì—‘ì…€ ë°˜ì˜ (CRITICAL - ì¦‰ì‹œ ì‹¤í–‰)
ì‚¬ìš©ìê°€ ì•„ë˜ì²˜ëŸ¼ ê¸ì • ì‘ë‹µí•˜ë©´ **ë‹¤ì‹œ í™•ì¸ ìš”ì²­í•˜ì§€ ë§ê³  ì¦‰ì‹œ** write_company_diagnosis_report í˜¸ì¶œ:
- "ì‘", "ë„¤", "ì¢‹ì•„", "ì§„í–‰í•´", "ë°˜ì˜í•´ì¤˜", "ì €ì¥í•´ì¤˜", "ì—‘ì…€ë¡œ ë§Œë“¤ì–´ì¤˜", "OK"

write_company_diagnosis_reportì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•´ í˜¸ì¶œ:
- excel_path (temp ë‚´ë¶€ ê²½ë¡œ)
- scores (6ê°œ í•­ëª© ì ìˆ˜)
- summary_text, improvement_text
- (ì„ íƒ) company_name, report_datetime, output_filename

## ë‹µë³€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

**ì´ ë¬¸ì„œëŠ” í”„ë¡œê·¸ë¨ ìš´ì˜/íˆ¬ìê²€í†  ë¬¸ì„œë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.**

- ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€
- ë‹¨ì •/ê³¼ì¥ ê¸ˆì§€, ê·¼ê±° ì¤‘ì‹¬
- í‘œ/ë¶ˆë¦¿ìœ¼ë¡œ êµ¬ì¡°í™”
- â€œ~í•˜ê² ìŠµë‹ˆë‹¤â€ë¡œ ëë‚´ì§€ ë§ê³ , ê°€ëŠ¥í•œ ê²½ìš° ë„êµ¬ë¥¼ ì‹¤í–‰í•´ ê²°ê³¼ê¹Œì§€ ì œê³µ

í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ê³  ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
"""

	    # ========================================
	    # Chat Mode (ëŒ€í™”í˜•)
	    # ========================================

    async def chat(self, user_message: str, mode: str = "exit") -> AsyncIterator[str]:
        """
        ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ (ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            mode: "exit" (Exit í”„ë¡œì ì…˜) ë˜ëŠ” "peer" (Peer PER ë¶„ì„)

        Yields:
            str: ì—ì´ì „íŠ¸ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
        """

        # ë„êµ¬ í˜¸ì¶œ ì¹´ìš´í„° ì´ˆê¸°í™” (ìƒˆ ë©”ì‹œì§€ë§ˆë‹¤)
        self._tool_step_count = 0

        # í˜„ì¬ ëª¨ë“œ ì €ì¥
        self._current_mode = mode

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.memory.add_message("user", user_message)

        # ë§ˆì§€ë§‰ ì¸í„°ë™ì…˜ ì €ì¥
        self.last_interaction["user_message"] = user_message
        self.last_interaction["assistant_response"] = ""
        self.last_interaction["context"] = {"mode": mode}

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)
        system_prompt = self._build_system_prompt(mode)

        # Claude API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
        async with self.async_client.messages.stream(
            model=self.model,
            system=system_prompt,
            messages=self.conversation_history,
            tools=self.tools,
            max_tokens=8192
        ) as stream:

            async for event in stream:
                # í…ìŠ¤íŠ¸ ì¶œë ¥
                if event.type == "content_block_delta":
                    if hasattr(event.delta, 'text'):
                        yield event.delta.text

                # ë„êµ¬ ì‚¬ìš©
                elif event.type == "content_block_stop":
                    message = await stream.get_final_message()

                    # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
                    if hasattr(message, 'usage'):
                        self.token_usage["total_input_tokens"] += message.usage.input_tokens
                        self.token_usage["total_output_tokens"] += message.usage.output_tokens
                        self.token_usage["session_calls"] += 1

                    # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
                    tool_results = []
                    assistant_response_parts = []

                    for content_block in message.content:
                        if content_block.type == "text":
                            assistant_response_parts.append(content_block.text)
                        elif content_block.type == "tool_use":
                            tool_name = content_block.name
                            tool_input = content_block.input

                            yield f"\n\n**ë„êµ¬: {tool_name}** ì‹¤í–‰ ì¤‘...\n"

                            # ë„êµ¬ ì‹¤í–‰
                            tool_result = execute_tool(tool_name, tool_input)

                            # ê²°ê³¼ ì €ì¥
                            tool_results.append({
                                "type": "tool_result",
                                "tool_use_id": content_block.id,
                                "content": json.dumps(tool_result, ensure_ascii=False)
                            })

                            # ë©”ëª¨ë¦¬/ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ê³µí†µ í—¬í¼)
                            self._record_tool_usage(tool_name, tool_input, tool_result)

                            tool_ok = not (isinstance(tool_result, dict) and tool_result.get("success") is False)
                            yield f"**ë„êµ¬: {tool_name}** {'ì™„ë£Œ' if tool_ok else 'ì‹¤íŒ¨'}\n\n"

                    # Assistant ì‘ë‹µ ë©”ëª¨ë¦¬ì— ì €ì¥
                    if assistant_response_parts:
                        full_response = "\n".join(assistant_response_parts)
                        self.memory.add_message("assistant", full_response)
                        self.last_interaction["assistant_response"] = full_response

                    # ë„êµ¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ëŒ€í™” ê³„ì†
                    if tool_results:
                        # Assistant ë©”ì‹œì§€ ì¶”ê°€
                        self.conversation_history.append({
                            "role": "assistant",
                            "content": message.content
                        })

                        # Tool ê²°ê³¼ ì¶”ê°€
                        self.conversation_history.append({
                            "role": "user",
                            "content": tool_results
                        })

                        # Claude ë‹¤ìŒ ì‘ë‹µ ìƒì„±
                        async for text in self._continue_conversation():
                            yield text

    async def _continue_conversation(self) -> AsyncIterator[str]:
        """ë„êµ¬ ì‹¤í–‰ í›„ ëŒ€í™” ê³„ì†"""

        # ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ ì œí•œ í™•ì¸ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        self._tool_step_count += 1
        if self._tool_step_count > MAX_TOOL_STEPS:
            logger.warning(f"Tool step limit reached: {MAX_TOOL_STEPS}")
            yield "\n\n[ì‹œìŠ¤í…œ] ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê³„ì†í•˜ì„¸ìš”."
            return

        # ì €ì¥ëœ ëª¨ë“œ ì‚¬ìš©
        mode = getattr(self, '_current_mode', 'exit')
        system_prompt = self._build_system_prompt(mode)

        async with self.async_client.messages.stream(
            model=self.model,
            system=system_prompt,
            messages=self.conversation_history,
            tools=self.tools,
            max_tokens=8192
        ) as stream:

            async for event in stream:
                if event.type == "content_block_delta":
                    if hasattr(event.delta, 'text'):
                        yield event.delta.text

                # ì¶”ê°€ ë„êµ¬ í˜¸ì¶œ (ì¬ê·€ì  ì²˜ë¦¬)
                elif event.type == "content_block_stop":
                    message = await stream.get_final_message()

                    # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
                    if hasattr(message, 'usage'):
                        self.token_usage["total_input_tokens"] += message.usage.input_tokens
                        self.token_usage["total_output_tokens"] += message.usage.output_tokens
                        self.token_usage["session_calls"] += 1

                    tool_results = []
                    for content_block in message.content:
                        if content_block.type == "tool_use":
                            tool_name = content_block.name
                            tool_input = content_block.input

                            yield f"\n\n**ë„êµ¬: {tool_name}** ì‹¤í–‰ ì¤‘...\n"

                            tool_result = execute_tool(tool_name, tool_input)

                            tool_results.append({
                                "type": "tool_result",
                                "tool_use_id": content_block.id,
                                "content": json.dumps(tool_result, ensure_ascii=False)
                            })

                            # ë©”ëª¨ë¦¬/ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì¬ê·€ í˜¸ì¶œì—ì„œë„ ê¸°ë¡)
                            self._record_tool_usage(tool_name, tool_input, tool_result)

                            tool_ok = not (isinstance(tool_result, dict) and tool_result.get("success") is False)
                            yield f"**ë„êµ¬: {tool_name}** {'ì™„ë£Œ' if tool_ok else 'ì‹¤íŒ¨'}\n\n"

                    if tool_results:
                        self.conversation_history.append({
                            "role": "assistant",
                            "content": message.content
                        })

                        self.conversation_history.append({
                            "role": "user",
                            "content": tool_results
                        })

                        async for text in self._continue_conversation():
                            yield text

    def _record_tool_usage(self, tool_name: str, tool_input: dict, tool_result: dict):
        """ë„êµ¬ ì‚¬ìš© ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬/ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë¡ (ê³µí†µ í—¬í¼)"""
        # ë©”ëª¨ë¦¬ì— ë„êµ¬ ì‚¬ìš© ê¸°ë¡
        self.memory.add_message("tool", f"ë„êµ¬ ì‚¬ìš©: {tool_name}", {
            "tool_name": tool_name,
            "input": tool_input,
            "result": tool_result
        })

        # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ - ë¶„ì„ íŒŒì¼
        if tool_name in ["analyze_excel", "read_excel_as_text", "analyze_company_diagnosis_sheet"]:
            if tool_result.get("success"):
                file_path = tool_input.get("excel_path")
                if file_path and file_path not in self.context["analyzed_files"]:
                    self.context["analyzed_files"].append(file_path)
                    self.memory.add_file_analysis(file_path)
                self.context["last_analysis"] = tool_result

        # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ - PDF ë¶„ì„
        if tool_name == "read_pdf_as_text":
            if tool_result.get("success"):
                file_path = tool_input.get("pdf_path")
                if file_path and file_path not in self.context["analyzed_files"]:
                    self.context["analyzed_files"].append(file_path)
                    self.memory.add_file_analysis(file_path)

        # ìƒì„± íŒŒì¼ ê¸°ë¡
        if tool_name in ["analyze_and_generate_projection", "generate_exit_projection", "write_company_diagnosis_report"]:
            if tool_result.get("success"):
                output_file = tool_result.get("output_file")
                if output_file:
                    self.memory.add_generated_file(output_file)

    # ========================================
    # Utility Methods
    # ========================================

    def chat_sync(self, user_message: str, mode: str = "exit") -> str:
        """ë™ê¸° ë²„ì „ chat (ê°„ë‹¨í•œ ì‚¬ìš©)

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            mode: "exit" (Exit í”„ë¡œì ì…˜) ë˜ëŠ” "peer" (Peer PER ë¶„ì„)

        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ ë¬¸ìì—´
        """
        import asyncio

        async def run():
            response = ""
            async for chunk in self.chat(user_message, mode=mode):
                response += chunk
            return response

        # Python 3.10+ compatible: asyncio.run() ì‚¬ìš©
        # ë‹¨, ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ nest_asyncio í•„ìš”
        try:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
            loop = asyncio.get_running_loop()
            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ (ì˜ˆ: Jupyter, Streamlit)
            # nest_asyncio ë˜ëŠ” ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as pool:
                future = pool.submit(asyncio.run, run())
                return future.result()
        except RuntimeError:
            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ asyncio.run() ì‚¬ìš©
            return asyncio.run(run())

    def get_token_usage(self) -> Dict[str, Any]:
        """í† í° ì‚¬ìš©ëŸ‰ ë° ì˜ˆìƒ ë¹„ìš© ë°˜í™˜"""
        # Claude Opus 4.5 ê°€ê²© (2024ë…„ ê¸°ì¤€)
        INPUT_PRICE_PER_1M = 15.0   # $15 / 1M input tokens
        OUTPUT_PRICE_PER_1M = 75.0  # $75 / 1M output tokens

        input_cost = (self.token_usage["total_input_tokens"] / 1_000_000) * INPUT_PRICE_PER_1M
        output_cost = (self.token_usage["total_output_tokens"] / 1_000_000) * OUTPUT_PRICE_PER_1M
        total_cost = input_cost + output_cost

        return {
            "input_tokens": self.token_usage["total_input_tokens"],
            "output_tokens": self.token_usage["total_output_tokens"],
            "total_tokens": self.token_usage["total_input_tokens"] + self.token_usage["total_output_tokens"],
            "api_calls": self.token_usage["session_calls"],
            "estimated_cost_usd": round(total_cost, 4),
            "estimated_cost_krw": round(total_cost * 1400, 0)  # ëŒ€ëµì  í™˜ìœ¨
        }

    def reset_token_usage(self):
        """í† í° ì‚¬ìš©ëŸ‰ ì´ˆê¸°í™”"""
        self.token_usage = {
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "session_calls": 0
        }

    def reset(self):
        """ì„¸ì…˜ ì´ˆê¸°í™”"""
        self.conversation_history = []
        self.context = {
            "analyzed_files": [],
            "cached_results": {},
            "last_analysis": None
        }
        self.reset_token_usage()
